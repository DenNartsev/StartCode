{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для ответа на вопрос о скорости обучения код взят отсюда\n",
    "#https://github.com/Intelligent-Systems-Phystech/StartCode/blob/master/Agafonov2018ProblemMinist/MinistSolution.ipynb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def drow_acc(history) :\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.grid(True)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def drow_loss(history) :\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.grid(True)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def neural_net (model):\n",
    "    model.add(Dense(25, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    hist = model.fit(x_train, y_train, epochs=500, validation_data=(x_test,y_test))\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.txt', sep = ',', names = ['Class','Alcohol', 'Malic acid',\n",
    " 'Ash',\n",
    "'Alcalinity of ash',  \n",
    " 'Magnesium',\n",
    "'Total phenols',\n",
    " 'Flavanoids',\n",
    "'Nonflavanoid phenols',\n",
    " 'Proanthocyanins',\n",
    "'Color intensity',\n",
    " 'Hue',\n",
    " 'OD280/OD315 of diluted wines',\n",
    " 'Proline'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 4s 28ms/step - loss: 31.3608 - acc: 0.0000e+00 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 63us/step - loss: 29.6206 - acc: 0.0125 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: 30.3661 - acc: 0.0062 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 30.1887 - acc: 0.0062 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: 30.1859 - acc: 0.0125 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: 30.5892 - acc: 0.0062 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: 29.6185 - acc: 0.0062 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: 28.1484 - acc: 0.0062 - val_loss: 27.4630 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: 26.8188 - acc: 0.0125 - val_loss: 19.1515 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: 17.5465 - acc: 0.0375 - val_loss: 4.4227 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: 11.5742 - acc: 0.1000 - val_loss: -2.7195 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -2.4595 - acc: 0.2625 - val_loss: -9.0510 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -9.3428 - acc: 0.2938 - val_loss: -11.3599 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -12.3616 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -12.6068 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -13.2630 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -13.4557 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -13.5103 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.5041 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.3994 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -14.6945 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -13.6924 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.0696 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.4687 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.7953 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.7099 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.4041 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -14.9216 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0049 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.0327 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.0763 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0279 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.7593 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.9906 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -14.4750 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -14.8825 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.5261 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3240 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1942 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.8457 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2980 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0606 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.9463 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1700 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2462 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1273 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.0977 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1231 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2801 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1459 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2826 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1353 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1787 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1108 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2672 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2106 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -14.9582 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1574 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1906 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2414 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2922 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3220 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1601 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2648 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3131 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2277 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3308 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1077 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1024 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1161 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3143 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.0152 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1817 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2998 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2089 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2905 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2850 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3370 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2599 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2434 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2198 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3204 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3237 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3066 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2940 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3059 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3099 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3231 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1460 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3412 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3261 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2437 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3324 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3210 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3244 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3261 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3412 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1319 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3294 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3412 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2438 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3296 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2237 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3412 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3345 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.2439 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3265 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2439 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3224 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3261 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3213 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3138 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3229 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1467 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1435 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2408 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2441 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1469 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3296 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3411 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3281 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1470 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2246 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1429 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1472 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1473 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3345 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2444 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1474 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3414 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3346 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1477 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1477 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1478 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1478 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1480 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2448 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1481 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1481 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1410 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -14.9522 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2450 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -14.9527 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1458 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2452 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.1489 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1490 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2425 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2454 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2454 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1493 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2455 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2456 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.0506 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2457 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1497 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2458 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1498 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2458 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3418 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "178/178 [==============================] - 0s 22us/step\n",
      "\n",
      "acc: 33.15%\n"
     ]
    }
   ],
   "source": [
    "X_col = [col for col in data.columns if col != 'Class']\n",
    "X = data[X_col]\n",
    "Y = data['Class']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 10)\n",
    "model = Sequential()\n",
    "hist = neural_net (model)\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drow_acc(hist)\n",
    "drow_loss(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 0.33\n",
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 1s 4ms/step - loss: -13.9800 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -13.6019 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.5394 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.8032 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1042 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1255 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.5021 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.3787 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2489 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2227 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.9226 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.0200 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0033 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.7618 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.1962 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.0945 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.0895 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1479 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.2436 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1178 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -14.8687 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -14.8952 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2388 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.0464 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.0329 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3305 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.9515 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9510 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2454 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3442 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1632 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2393 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3406 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2519 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -14.9854 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2651 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9966 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.0059 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1795 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.1000 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2590 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1665 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3438 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2583 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2728 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2019 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3444 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2727 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2110 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2504 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.0868 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3116 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2701 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1291 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2861 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2354 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3408 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2790 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3059 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2944 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3242 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2885 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3324 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3148 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3315 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3411 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3316 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3315 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3062 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3272 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1455 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 250us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 275us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.2437 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "part 0.665\n",
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 29.6363 - acc: 0.0000e+00 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: 28.3573 - acc: 0.0062 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: 28.4710 - acc: 0.0125 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: 26.2412 - acc: 0.0312 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: 24.8075 - acc: 0.0500 - val_loss: 27.2159 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: 11.8936 - acc: 0.0750 - val_loss: -2.5351 - val_acc: 0.1667\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -0.7458 - acc: 0.1812 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -5.3528 - acc: 0.2063 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -6.7913 - acc: 0.2625 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -7.0654 - acc: 0.2875 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -7.4085 - acc: 0.2750 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -11.0276 - acc: 0.2563 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -11.4673 - acc: 0.2812 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.1771 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.2070 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4457 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.2600 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.4401 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.8349 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.3345 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.6416 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.6416 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.3364 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.8379 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.4401 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.7393 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.7590 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.2307 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.3394 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -11.7323 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -13.1371 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -14.7423 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.6416 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.7352 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.9356 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -14.3394 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.8431 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.7382 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.7423 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.7371 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.2397 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.5349 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.8360 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.1371 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.5378 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.5368 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.6386 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.2408 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.2337 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.7382 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.6345 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.0364 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.1084 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.6356 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.2367 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.9397 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.3705 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.5378 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.2408 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.0364 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4371 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.6345 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.3405 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.6356 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.4341 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.5408 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.3375 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.5378 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -12.5338 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.7382 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4371 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.9345 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.9427 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.7382 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.4412 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.3405 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.6375 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.6345 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.7382 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4382 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.0404 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 150us/step - loss: -12.9345 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.7382 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.9093 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.3405 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.0393 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4371 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -13.5378 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -13.5389 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -13.4382 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.8379 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.7382 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.5378 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.9356 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.6224 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4382 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.9356 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.0353 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.3364 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.3375 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.0393 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.8379 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.6386 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.3364 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.5389 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.1401 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.7423 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.0393 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.4401 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.8941 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.5378 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.3364 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.7412 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.7423 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -12.4341 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.9356 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.7423 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.1390 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.0382 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.8349 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.3375 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.8071 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.1401 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.9367 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -12.1330 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.0761 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.6364 - acc: 0.2938 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.9345 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.5408 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -12.7352 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.2517 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -12.6334 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -11.6315 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.1992 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.6386 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -12.3334 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.0423 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -11.8461 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.0398 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.2438 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.1360 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.0393 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.9386 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4371 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.4401 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.8379 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -12.6743 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -12.7341 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.8390 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.1401 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.8390 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.2378 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.4341 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.0323 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.2367 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.4382 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.7393 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.2367 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.6386 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.0364 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.5408 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.6386 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.3405 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.0423 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.1093 - acc: 0.3000 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.7393 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.2393 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.1390 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.3546 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.5711 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.3375 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -10.1685 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.9386 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -13.6386 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.2417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -11.1118 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.2616 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.1222 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.7134 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.2590 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.3926 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.2148 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.4851 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1059 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.8584 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.6715 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1049 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.5363 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.7107 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3135 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1308 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -14.9800 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.7045 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2816 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.0046 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.9776 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.3377 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3302 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2094 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2384 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.0891 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.0526 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.2078 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.1231 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1098 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.9993 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.1166 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2438 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3440 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2308 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2437 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.0546 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3439 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2440 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3444 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2597 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1682 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2583 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.8188 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.0903 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2110 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1630 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -14.9623 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2491 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2500 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1698 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2486 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2519 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2530 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1475 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1871 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1818 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1674 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2312 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.0258 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2021 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.0304 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1372 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2448 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2280 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -14.9164 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2248 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2711 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1162 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9994 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1336 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1142 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2140 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2436 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2046 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3019 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1671 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2249 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2172 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2898 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1113 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2878 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2202 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2904 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2455 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2980 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2838 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3171 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1872 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3171 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3227 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1006 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3239 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2987 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3154 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1499 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0486 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.1333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1501 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3058 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3131 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3164 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2461 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1457 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1505 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3348 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2463 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3405 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2464 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.2464 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.0528 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1510 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2465 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.0532 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1513 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2467 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3252 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2468 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3324 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2469 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2469 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1518 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2470 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2470 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1520 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "part 1.0\n",
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 30.1511 - acc: 0.0062 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: 30.8167 - acc: 0.0125 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 31.0731 - acc: 0.0062 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 30.6510 - acc: 0.0000e+00 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 29.0611 - acc: 0.0312 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 21.6352 - acc: 0.0438 - val_loss: 27.7589 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 19.1248 - acc: 0.0813 - val_loss: 27.5397 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 17.4387 - acc: 0.0938 - val_loss: 21.5402 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: 6.1718 - acc: 0.1562 - val_loss: -8.6606 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -8.2339 - acc: 0.2875 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.8294 - acc: 0.2938 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.0393 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.6640 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -13.4431 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -12.7695 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -13.4920 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.4402 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.8922 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.3256 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.4785 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -13.9010 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.7906 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -13.7232 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.1321 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.4484 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.4358 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -13.6221 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.4412 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.5616 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.1752 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -13.7036 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -12.9220 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.1465 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.6967 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -13.7919 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -13.5741 - acc: 0.3062 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0911 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9523 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.8743 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.6647 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.7592 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0049 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2846 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.8924 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 75us/step - loss: -15.2633 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2564 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2111 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2764 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2380 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2128 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2928 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3374 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2919 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1444 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2427 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2768 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3376 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2607 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0809 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2673 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3266 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2574 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2430 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3404 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2779 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1451 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3399 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2660 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1452 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3135 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3411 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.0198 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3212 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2433 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3111 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3382 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3345 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3179 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2877 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3268 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3405 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2435 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2425 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1460 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2350 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2437 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3404 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2389 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3401 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1464 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1465 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3139 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1427 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3405 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1469 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1470 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1472 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -14.8106 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3372 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3114 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3410 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.2446 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1478 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1454 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2447 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1461 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1482 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1483 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3125 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1486 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3416 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1487 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1488 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3290 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3155 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1491 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1492 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3204 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2456 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1496 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1496 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3418 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2458 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2459 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2459 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2460 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0517 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1505 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1507 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2464 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2465 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2465 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1486 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1513 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2443 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2469 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2368 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1476 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3308 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3276 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3421 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3421 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3421 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2472 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2473 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2473 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1526 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1528 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2476 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3423 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3423 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3423 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3423 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1533 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1534 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2480 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2481 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1539 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3424 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1541 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3424 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2462 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2463 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3424 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3424 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2486 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1548 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2487 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2488 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3425 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1552 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    }
   ],
   "source": [
    "hist_list = []\n",
    "\n",
    "for part in np.linspace(0.33,1,num=3) :\n",
    "    print('part %s' % part)\n",
    "    element_cnt = int(x_train.shape[0] * part)\n",
    "    x_part_train = x_train[ :element_cnt]\n",
    "    y_part_train = y_train[ :element_cnt]\n",
    "    model = Sequential()\n",
    "    hist = neural_net (model)\n",
    "    hist_list.append(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAFNCAYAAABbpPhvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd8XFed9/HPudPUiyVZ7iWOU+z02EkgIZiWhBAIEELn4WFhAwu72X2WDS2wu7D0XgIsSQgESAECIQHSi9ITO9W99yrb6mXqPc8fZ0YzkmVblmYyY+X7fr1gZu7cmXtmjhV99Tvn3GustYiIiIhIafGK3QAREREROZBCmoiIiEgJUkgTERERKUEKaSIiIiIlSCFNREREpAQppImIiIiUIIU0EXnFMsb82hjz1RHuu9kY88axvo+IyEgppImIiIiUIIU0ERERkRKkkCYiJS09zHiVMWapMabXGPNLY0yzMeZuY0y3MeYBY0x9zv5vM8asMMZ0GGNajDEn5jx3ujHm+fTrfg+UDTnWJcaYF9OvfdIYc8oo2/yPxpj1xpg2Y8ydxpgp6e3GGPMDY0yrMaYz/ZlOSj93sTFmZbptO4wx/zGqL0xExg2FNBE5GlwGvAk4DngrcDfwBaAR99+xKwGMMccBtwD/BjQBdwF/NcaEjTFh4C/Ab4EJwB/T70v6tWcANwAfBxqAXwB3GmMiR9JQY8zrgW8A7wYmA1uAW9NPXwCcn/4cdcB7gP3p534JfNxaWw2cBDx0JMcVkfFHIU1EjgY/sdbusdbuAB4DnrHWvmCtjQG3A6en93sP8Hdr7f3W2gTwXaAceDVwDhACfmitTVhrbwOW5BzjH4FfWGufsdamrLU3ArH0647EB4AbrLXPp9v3eeBVxphZQAKoBk4AjLV2lbV2V/p1CWCeMabGWtturX3+CI8rIuOMQpqIHA325NzvH+ZxVfr+FFzlCgBrrQ9sA6amn9thrbU5r92Sc38m8On0UGeHMaYDmJ5+3ZEY2oYeXLVsqrX2IeAa4KfAHmPMtcaYmvSulwEXA1uMMY8YY151hMcVkXFGIU1ExpOduLAFuDlguKC1A9gFTE1vy5iRc38b8DVrbV3O/yqstbeMsQ2VuOHTHQDW2h9ba88E5uOGPa9Kb19irb0UmIgblv3DER5XRMYZhTQRGU/+ALzFGPMGY0wI+DRuyPJJ4CkgCVxpjAkaY94JnJXz2uuATxhjzk5P8K80xrzFGFN9hG24GfiIMea09Hy2r+OGZzcbYxam3z8E9AJRIJWeM/cBY0xtepi2C0iN4XsQkXFAIU1Exg1r7Rrgg8BPgH24RQZvtdbGrbVx4J3A/wXacfPX/pzz2mdx89KuST+/Pr3vkbbhQeBLwJ9w1bs5wHvTT9fgwmA7bkh0P27eHMCHgM3GmC7gE+nPISKvYGbw9AwRERERKQWqpImIiIiUIIU0ERERkRKkkCYiIiJSghTSREREREqQQpqIiIhICQoWuwH50NjYaGfNmlXw4/T29lJZWVnw48jIqU9Kk/qlNKlfSo/6pDQVul+ee+65fdbapsPtNy5C2qxZs3j22WcLfpyWlhYWLVpU8OPIyKlPSpP6pTSpX0qP+qQ0FbpfjDFbDr+XhjtFRERESpJCmoiIiEgJUkgTERERKUEKaSIiIiIlSCFNREREpAQppImIiIiUIIU0ERERkRKkkCYiIiJSghTSREREREqQQtoRsNayeNdiEn6i2E0RERGRcU4h7Qg81P0QH73vo/xy2S+L3RQREREZ5xTSRmhHzw7ubL+TgAlwy+pbiKVixW6SiIiIjGNFC2nGmDJjzGJjzEvGmBXGmC+nt882xjxjjFlnjPm9MSZcrDbmatnWgo/P1edcTVu0jUe2PVLsJomIiMg4VsxKWgx4vbX2VOA04CJjzDnAt4AfWGvnAu3AR4vYxgGP7XiMicGJXHLMJQBs6RrRBexFRERERqVoIc06PemHofT/LPB64Lb09huBtxeheYNEk1Ge3f0s88rnUR4spz5Sz87encVuloiIiIxjRZ2TZowJGGNeBFqB+4ENQIe1NpneZTswtVjty1jbvpaUTTGvfB4Ak6sms6tnV5FbJSIiIuOZsdYWuw0YY+qA24H/BH5lrT02vX06cJe19uRhXnMFcAVAc3PzmbfeemtB2xj1o8R6Y9RW13L93uvZk9jD1VOuLugx5fB6enqoqqoqdjNkCPVLaVK/lB71SWkqdL+87nWve85au+Bw+wUL1oIjYK3tMMa0AOcAdcaYYLqaNg0YdlzRWnstcC3AggUL7KJFiwrXwL1r4G//zvMT3sYZiy5l8ZLF3Lb2Nl772tdijCncceWwWlpaKGjfy6ioX0qT+qX0qE9KU6n0SzFXdzalK2gYY8qBNwKrgIeBd6V3+zBwR3FamCNUDlsep7LXLRaYXDmZ/mQ/HbGOIjdMRERExqtizkmbDDxsjFkKLAHut9b+Dfgs8O/GmPVAA1D8M8fWTINAhPL+HQBMqZwCoMUDIiIiUjBFG+601i4FTh9m+0bgrJe/RYfgedAwh4o+F8omV00GYFfPLuY3zC9my0RERGSc0hUHRqphDhV9rpI2oWwCAJ2xzmK2SERERMYxhbSRaphLWXQ3pJKEvBCALrQuIiIiBaOQNlINx+LZFNz7ecJJF87iqXiRGyUiIiLjVUmcguOo0HCsu118LaFJ7rRtcV8hTURERApDlbSRmraQjbM/AEC4rw3QcKeIiIgUjkLaSHkeW2dcDsEyvL59BE2QREohTURERApDIe1IGAOVTdC7j1AgpEqaiIiIFIxC2pGqbITevYS8kBYOiIiISMEopB2pyqaBkKZKmoiIiBSKQtqRSg93hgNhVdJERESkYBTSjlR6uDPshXUKDhERESkYhbQjVdkEqTgh45H0k8VujYiIiIxTCmlHqrIJgJAxGu4UERGRglFIO1KVjQCErE5mKyIiIoWjkHak0pW0sLWqpImIiEjBKKQdqerJAIRSSVXSREREpGAU0o5UZROEKggnY6qkiYiISMEopB0pY6B+FuFEVJU0ERERKRiFtNGon0Uw0aeQJiIiIgWjkDYa9bMIx3o03CkiIiIFo5A2GvWzCKUSJJKxYrdEREREximFtNGon03YQjwVLXZLREREZJxSSBuN+pmEsJqTJiIiIgWjkDYa4UrC1pLwU8VuiYiIiIxTCmmj4QUJWUsSH9/6xW6NiIiIjEMKaaPhBQlZd1dDniIiIlIICmmj4QUIW5fSdBoOERERKQSFtNFID3eCKmkiIiJSGAppo2FUSRMREZHCUkgbDS9ImHQlLaVKmoiIiOSfQtpoaOGAiIiIFJhC2mh43kBIi/sa7hQREZH8U0gbpVD6q9Nwp4iIiBSCQtoohY376lRJExERkUJQSBulUCakaXWniIiIFIBC2ihlKmlaOCAiIiKFoJA2SmETADQnTURERApDIW2UQpmQpkqaiIiIFIBC2ihlQpoWDoiIiEghKKSNUma4M5aKFbklIiIiMh4ppI1STfqr64p1FbklIiIiMh4ppI1SuReiDENHrKPYTREREZFxKFjsBhy1vCC1+AppIiIiUhCqpI2WF6TeBOiIKqSJiIhI/hUtpBljphtjHjbGrDLGrDDG/Gt6+wRjzP3GmHXp2/pitfGQvAC1eKqkiYiISEEUs5KWBD5trT0ROAf4lDFmHvA54EFr7VzgwfTj0uMFqbcKaSIiIlIYRQtp1tpd1trn0/e7gVXAVOBS4Mb0bjcCby9OCw/DC1CrhQMiIiJSICUxJ80YMws4HXgGaLbW7gIX5ICJxWvZIXhB6q2hM9ZJyk8VuzUiIiIyzhR9dacxpgr4E/Bv1touY8xIX3cFcAVAc3MzLS0tBWtjRk9Pz8BxTu3sJhKOYist9zx8D5WByoIfXw6U2ydSOtQvpUn9UnrUJ6WpVPqlqCHNGBPCBbSbrLV/Tm/eY4yZbK3dZYyZDLQO91pr7bXAtQALFiywixYtKnh7W1paGDjOtkYmx1uBOPMWzGN27eyCH18ONKhPpGSoX0qT+qX0qE9KU6n0SzFXdxrgl8Aqa+33c566E/hw+v6HgTte7raNiBekzrcAdMY6i9wYERERGW+KWUk7F/gQsMwY82J62xeAbwJ/MMZ8FNgKXF6k9h2aF6TO9wFoj7YXuTEiIiIy3hQtpFlrHwcONgHtDS9nW0bFeAOVNK3wFBERkXwridWdRyUvSEPKrerc27+3yI0RERGR8UYhbbS8IGW+T32knt29u4vdGhERERlnFNJGywuCn2RS5SSFNBEREck7hbTR8oLgp2iuaGZ3n0KaiIiI5JdC2mh5AfCTNFc2q5ImIiIieaeQNlrpkDapchLd8W76En3FbpGIiIiMIwppo5UzJw1QNU1ERETySiFttLwgWJ9JFQppIiIikn8KaaOVM9wJaPGAiIiI5JVC2milhztrIjUA9CZ6i9wgERERGU8U0kbLuEpa0LgrayX9ZJEbJCIiIuOJQtpopeekBdKXH03ZVJEbJCIiIuOJQtpoea6CFkyHNFXSREREJJ8U0kbLC7gbawGFNBEREckvhbTRSlfSjE0RNEENd4qIiEheKaSNVjqk4ScJekFSvkKaiIiI5I9C2milhzvxUwS8AAk/Udz2iIiIyLiikDZaAyEtScAENNwpIiIieaWQNloa7hQREZECUkgbrUxISy8cSFqt7hQREZH8UUgbrZxKWsAL6BQcIiIiklcKaaM1ENJSbrhTc9JEREQkjxTSRsukv7r0wgFV0kRERCSfFNJGSwsHREREpIAU0kZrSEjTwgERERHJJ4W00RoIab6GO0VERCTvFNJGK/dktl5Aw50iIiKSVwppo5U73KkLrIuIiEieKaSNVk4lLegFNdwpIiIieaWQNlq5J7M1AS0cEBERkbxSSButgctC+ToFh4iIiOSdQtpoDVk4oOFOERERySeFtNHSwgEREREpIIW00Rp6MltV0kRERCSPFNJGy2SGO1Ma7hQREZG8U0gbrdw5aSag4U4RERHJK4W00RoY7kwR8kJa3SkiIiJ5pZA2WjpPmoiIiBSQQtpo5YY0zUkTERGRPFNIG62c4c6gp1NwiIiISH4ppI2Wl/7q0udJUyVNRERE8kkhbbSGDHdq4YCIiIjkk0LaaA1cu9MNdyZtEmttcdskIiIi44ZC2mgNWd0JaF6aiIiI5I1C2mjlXHEgmA5sCmkiIiKSL0UNacaYG4wxrcaY5TnbJhhj7jfGrEvf1hezjQfleWC8gYUDgOaliYiISN4Uu5L2a+CiIds+BzxorZ0LPJh+XJpMYGDhAEDCTxS5QSIiIjJeFDWkWWsfBdqGbL4UuDF9/0bg7S9ro46EF9ScNBERESmIYlfShtNsrd0FkL6dWOT2HJwXBN/PzknTcKeIiIjkSbDYDRgtY8wVwBUAzc3NtLS0FPyYPT09g45zrm/Zs20zGxLVADz25GNMCE4oeDska2ifSGlQv5Qm9UvpUZ+UplLpl1IMaXuMMZOttbuMMZOB1uF2stZeC1wLsGDBArto0aKCN6ylpYVBx1lcxrTJk5h3wjx4AhaevZDp1dML3g7JOqBPpCSoX0qT+qX0qE9KU6n0SykOd94JfDh9/8PAHUVsy6Gl56RpuFNERETyrdin4LgFeAo43hiz3RjzUeCbwJuMMeuAN6UflyYvAH5qYHWnrt8pIiIi+TKi4U5jzL8CvwK6geuB04HPWWvvG8vBrbXvO8hTbxjL+75svMDg86RpdaeIiIjkyUgraf9gre0CLgCagI9QyhWul4sXHLh2J0DSqpImIiIi+THSkGbStxcDv7LWvpSz7ZVryHnSNNwpIiIi+TLSkPacMeY+XEi71xhTDfiFa9ZRIhPS0nPStHBARERE8mWkp+D4KHAasNFa22eMmYAb8nxlSy8cCHkhQHPSREREJH9GWkl7FbDGWtthjPkg8EWgs3DNOkpkrt1pdO1OERERya+RhrSfA33GmFOBzwBbgN8UrFVHCw13ioiISIGMNKQlrbUWd/HzH1lrfwRUF65ZRwkvCH52daeGO0VERCRfRjonrdsY83ngQ8BrjDEBIFS4Zh0lMiEtfZ40re4UERGRfBlpJe09QAx3vrTdwFTgOwVr1dHCGzwnTedJExERkXwZUUhLB7ObgFpjzCVA1FqrOWm6dqeIiIgUyIhCmjHm3cBi4HLg3cAzxph3FbJhR4VMJU3X7hQREZE8G+mctKuBhdbaVgBjTBPwAHBboRp2VBgyJ00LB0RERCRfRjonzcsEtLT9R/Da8csLDL52pyppIiIikicjraTdY4y5F7gl/fg9wF2FadJRZMh50hTSREREJF9GFNKstVcZYy4DzsVdWP1aa+3tBW3Z0WDIwgGFNBEREcmXkVbSsNb+CfhTAdty9MlU0tKn4PCtrjkvIiIi+XHIkGaM6QbscE8B1lpbU5BWHS2Mu8B6JqRp4YCIiIjkyyFDmrVWl346lCEns1VIExERkXzRCs2xSJ+CwzPua1RIExERkXxRSBuL9Jy0TEjTnDQRERHJF4W0sUhX0owxBExAl4USERGRvFFIG4v0nDTAhTQNd4qIiEieKKSNRW5I81RJExERkfxRSBuL9Jw0AM94qqSJiIhI3iikjYUXBCz4PgET0MIBERERyRuFtLFIX7MTm9KcNBEREckrhbSxSF+zM3ORdYU0ERERyReFtLFIX2kgc640LRwQERGRfFFIG4vcSpqGO0VERCSPFNLGYiCkpbRwQERERPJKIW0sMgsH/JTOkyYiIiJ5pZA2FhruFBERkQJRSBuLnJDmGU/DnSIiIpI3Cmlj4WVXdwZMgKRNFrc9IiIiMm4opI1F7sIBTwsHREREJH8U0sZi6BUHtHBARERE8kQhbSy0cEBEREQKRCFtLLRwQERERApEIW0shsxJS/paOCAiIiL5oZA2Fib99aWHO1VJExERkXxRSBsLzUkTERGRAlFIG4shw50KaSIiIpIvCmljoYUDIiIiUiAKaWORW0kzWjggIiIi+VOyIc0Yc5ExZo0xZr0x5nPFbs+whlwWSpU0ERERyZeSDGnGmADwU+DNwDzgfcaYecVt1TCGhDTNSRMREZF8KcmQBpwFrLfWbrTWxoFbgUuL3KYD5a7u9HRZKBEREcmfUg1pU4FtOY+3p7eVlkxIs74WDoiIiEheBYvdgIMww2yzg3Yw5grgCoDm5mZaWloK3qienp5Bxynr38U5wKoVy2gNttIX7XtZ2iFZQ/tESoP6pTSpX0qP+qQ0lUq/lGpI2w5Mz3k8DdiZu4O19lrgWoAFCxbYRYsWFbxRLS0tDDpOx1Z4Bk48fi7Toh7rt63n5WiHZB3QJ1IS1C+lSf1SetQnpalU+qVUhzuXAHONMbONMWHgvcCdRW7TgYZecUBz0kRERCRPSrKSZq1NGmP+GbgXCAA3WGtXFLlZB8qEtFRCqztFREQkr0oypAFYa+8C7ip2Ow4pGHG3yRheUAsHREREJH9Kdbjz6BCqcLeJPlXSREREJK8U0sYiEAIv5EKazpMmIiIieaSQNlbhCoj36bJQIiIiklcKaWMVqhiopCWtLrAuIiIi+aGQNlbpkOYZ91WqmiYiIiL5oJA2VunhzqBxC2U1L01ERETyQSFtrIZU0rTCU0RERPJBIW2sMnPSTADQcKeIiIjkh0LaWIUqINFPwHMhTYsHREREJB8U0sYqXAHx3uzCAV+VNBERERk7hbSxSg93ZhYOqJImIiIi+aCQNlbp4U7P0yk4REREJH8U0sYqPdwZQCFNRERE8kchbaxC5WBTBNIPk76GO0VERGTsFNLGKlQJgJcOZ6qkiYiISD4opI1VuAKAYPpKA1o4ICIiIvmgkDZWIRfSvFQC0Ck4REREJD8U0sYqHdIC6ZCmy0KJiIhIPiikjVWoHIBAek6aQpqIiIjkg0LaWIXdwoFAMg5o4YCIiIjkh0LaWA0Md7pKmk7BISIiIvmgkDZWAwsHVEkTERGR/FFIG6twppLmQprmpImIiEg+KKSNVVktAIFYD6CQJiIiIvmhkDZW4UqoaCTQ0wroPGkiIiKSHwpp+VA/i0D3LkCVNBEREckPhbR8qJ+Fp5AmIiIieaSQlg/1swh07wEU0kRERCQ/FNLyoX4WgfQF1lO+QpqIiIiMnUJaPtTPIoAFdJ40ERERyQ+FtHyon0XAZTQNd4qIiEheKKTlQ+00vInzAUj1tRW5MSIiIjIeKKTlgzEELvo6AKnltxW5MSIiIjIeKKTlSaBhLgCpHUtg5wtFbo2IiIgc7RTS8iTgBQDwMbD2viK3RkRERI52Cml5EjAupKUCYYh1Fbk1IiIicrRTSMsTz7ivMhWMQLynyK0RERGRo51CWp4MVNKCEYh1F7k1IiIicrRTSMuTzJy0ZDACMVXSREREZGwU0vIkEogAEA+GVUkTERGRMQsWuwHjhWc8Ql6IGCHoV0gTERGRsVElLY8igQixQBDiCmkiIiIyNqqk5VEkECFmAxruFBERkTFTJS2PyoJlxDxPCwdERERkzIoS0owxlxtjVhhjfGPMgiHPfd4Ys94Ys8YYc2Ex2jdakUCEqOdBKgbJeLGbIyIiIkexYlXSlgPvBB7N3WiMmQe8F5gPXAT8zJj0CciOApFAhDjGPdAJbUVERGQMihLSrLWrrLVrhnnqUuBWa23MWrsJWA+c9fK2bvQigQjRdEbTpaFERERkLEptTtpUYFvO4+3pbUeFSDBCDN890Lw0ERERGYOCre40xjwATBrmqauttXcc7GXDbLMHef8rgCsAmpubaWlpGU0zj0hPT88hj9PT0UNvrBeAF55+lM66fQVv0yvd4frklay8bztz113P8pM+hx8oe1mPrX4pTeqX0qM+KU2l0i8FC2nW2jeO4mXbgek5j6cBOw/y/tcC1wIsWLDALlq0aBSHOzItLS0c6jh3ttzJxn3tAJw+fy7MLXybXukO1yevaM/9Gha/wPnzp8Gkk17WQ6tfSpP6pfSoT0pTqfRLqQ133gm81xgTMcbMBuYCi4vcphErC5QR9ZPugeakSbFF0/8GtYhFROSoVKxTcLzDGLMdeBXwd2PMvQDW2hXAH4CVwD3Ap6y1qWK0cTQiwQgxP+Ee6IS2UmzRTner+ZEiIkelolxxwFp7O3D7QZ77GvC1l7dF+REJ5IY0/WKUIstUc3WZMhGRo1KpDXce1SKBCLFUHAIR2L+u2M2RV7rMcGfmD4aunfCbt0OvFrSIiBwNFNLyqCxQRtyP489/Jyz9I/R3FLtJ8kqWGe7MzElb8kvY+DAsvq54bRIRkRFTSMujSDACQOysf4BELyz9Q5FbJK9osSGVtKqJ7rZ72AXTIiJSYhTS8igSSIe0xuOgohFaV47tDXc8B5sfz0PLpCBSSfjByfDcjcVuyfAGKmnpOWmp9PVku3YVpz0iInJEFNLyaCCkpWJQMwW6doztDR/6Kvzt3/PQMimIfWuhcyvseHbw9t+8HZ78SXHalGvonLTM487txWmPiIgcEYW0PBoU0mqnuYnaY9G7D9o3g++PvXEyOhsehkR0+Od2L3O3HdsGb9/4MNz3xdEf86Gvwe2fGP3rM2JD5qRlKmttG1wVUERESppCWh5lQlo0FXWVtINVLPZvgN79h3/D/nZIxfIzh2jXUvjdZQcPHHKgLU/Cb98Oj3138PZUEv7ySXjmf93jjq3udu/akfXroXTvgUe/DS/dMrZw7vvDVNLSIS0Vh7aNY2uniIgUnEJaHpUF3fURY8kY1EyFaAfEewfvlIjCT86Am951+Dfsd5eYon3zyBqQ6If2LcM/t7EF1j8A+9aM7L2G6twOt7wfWldlt7VthFRidO9XTJ074NYPHP5UFNuXuNue1sHb1z8AL94EO59Pv9928FNw/RvhwS9n90v0H3nbMsEPoHPbwfc7nHgPA5e9zcxJy70Kxq4XR//eIiLyslBIy6PBc9Kmuo1DhzzX3OVud7106DdLxrPDVG2b3G0img1uw3nqGrhmAbSuPvC5nj3udtNjcMc/u+pK9x53P3qQS1jFe93z7ZvhF+fDmr/D+gfdc31t8NOz3fUhD+XR78CGhw69z8tt1V9h9d/g/v869H470iHMG3LO5+dvBJPzo5OKwc4X3fDi3pzvfv/6g7/3lqfg+d8c2J9r73Xn2QM35220MlUzGFxJm34OhCqzAVREREqWQloeDZ6TNhUfeHfLldyy+pbsTi/8zt1OnHfoN+tvy97dv47ueDfc/Rn41izYc5BVo/s3uKGsv/7rgUNlmZB2/5fghd+6ie3P3uDuP/3z4d9vw0PZffvSw3iZULHrRXesTEUm3gfWDn59oh8e/oY7P1dGMnZk1bdU0gVWcNWqI61OJeOw7SCBZM1d2TbH++CeL8C+9XDze10w3vqUey7z3cX7XOBZey+c/U9wxofhvPTCjo0Pu9vcSubeQ1Qt7/xnuPNf4I8fyW7rb3crghekt40lpGWqZiaQMyetCyomwNQzYNtRc0lcEZFXLIW0PBo8J20qq8JhVvVu566N6eqZtbDtGXc/J4QNqy/7/H/veYRP3P8J2PSI2/Cnjw3/ms7tECyDbU/Dc78a/FwmaNh0eHvu15BMB55MmzKScXjkO7D2ngOfz7zPrqXudt86V6H5+mR4/PuD32fPSrCpwaciufGtcNdVw7d/ODdeAt87zt2/9wvw7WPgse8f+jW5Hv8B/PKNsD1nBWZfepizvw32LHf3190HT/8UrjkT1t4ND38t+1m7d7v/fX0yPPQ/7jNNOQ3e9mM4OT1svbHF3fbszh7nYCErlcyGuV0vZYPi1mcACydcAuUTDgx5e1ZkQ/7hZKqj1ZMHV9LKamH6We5zx/tG9l4iIlIUCml5NHAy26Q7BcdjFW6O2rK9S+nZ8KAbCov3uKGy3n0HVp4yNj0KK+8AwA9EeCLZzqq2VSQDIff83tXDV6O6dsJxF8Hs8+GB/x48lNa9Z/C+PbthxV/c/c2PD74g/IaH4OGvZgPBnhXutnoK9O519zMrG/eugeV/cvdX/33wMXang1zbJjd0moy5sLTuvoN/9lzJuKtm9be7179wEwTCbt7XugcO/3rITurPHXLNnYuWme83dP5g8GF4AAAgAElEQVTXzhfc7YRjXFjbmA7Iz/zC3VZPdre1093t5scOPHb7Fvj+PPjDh4ds3wR+Aqac7oJiJgxufRK8EExbAE3HZ0Na6yr37+Hnr4Y7PjX8ysyevfBiTsU2M9xZO3Xw6s5IDUw7C/wkbFc1TUSklCmk5VFZIL1wIBWDYITHm4+l3EIKn2dv+wD84f+4Haec7uYxxXvcL/A7PpV9Ez8Ff74CHvkmAOsnHUensST8BDv79rpfsjaVDR8Z1rrzstVOgwu/4Ya7ci//05MT0uZd6m470tWcVCwbQsCFiEHv7bt5UhNPcIHrh6fA8tvcc9EOePyH7n7NlMGvy4Q0LCy53lXmbMq1M7f9O190lShr3Zy57c+57Zseze7z/G/cBPjLfw2Nx8FNl8HPz8tWBpdcDz850w1X5kqmV7M+/DX43olu9WXfPneyYcie2HVo1Sozn2zWa9IhLT2caczgz1pWA43Hc4CKRhdou3bAynQY3rbEzRfMzFub/w53m6k0bnjIBbRQOcw811VEl1zvKo9//L/Z9x7u/HstX4e/fCK7ajNzjJp0SPNT7t9EWS3Mfg0Ey2HlnQe+j4iIlAyFtBGKJVP8bWOczr6Dz6fKnZN2x/o7eCm+jw+f8H4i1rK4PJId/pp8mrvt3et+gb/wu4HhqRXLbmJlLFvpea6ueeD+JhuFGedwd2UFP38pZxUguOHRZNSFtEknwXFvhpZvwo9Pd2fEj3YA6YAx9wKI1Lr7J7/bTSTf+LALTj8/z825AvcLvW6Gu18zBaqa3erQTLibdIq7zTweugpy9zJXfQO4/z8HD9Nm5ntZCzddDr+5FL450w1v3nSZq+w9mzOX7dkb3Hsdswje/wc46V2wZxmVvVtccLz3iy5Y/fYdrmKXkRsGu3fCnmWuktZ0gqtaZU5vsm8dTD8b3vJ9mPN6t61yIkw80c29y1QLM6EwU0kDOPsKDtAwZ3B1rq8Nbr7czSvMBKh5b3e3ratcRW/3MjjhLW7bos/B3Avh7s+6Kp3NmWO468XBw7fxPliWDs07nnfv8/DX3Hc16WT32pduAazr03AlHHchrLpT50sTESlhCmkj9ItHNnLb2gS/fXrzQffJhLQtXVv4ylNf4ezJZ3PFWf/BiRNPY0XDjOyOU053t62r+e/GCfywvhZW/Bke+ipffPZbfKmxYWDXpwMpalMpADaFQjzZOJ3PTGzkZ9vuwS77k1t9ueqvcMMF7gWZCs+FX4Oz/hHK6uCvV7ptmcUKE+dBc/p+41yYdZ47aevae12I2fiwCyyf3eLCHrjwV9mU/Qxn/l+4+DvZx/MudfO2bvsHWHO3W4m6e1m2agcu7HhBFxCX/9kFhD3LobcVpp4Jp7wbzv03N7x57SI3sf/Et7rX7lvrAocxMGE2XPA/ADTveQRufo9734u/664AkFsV7NwGx7/FTfQHF+h690FlI1RPcpU0a134nDgPFn4Umk9y+zYd74Jppu0ZZbUQrsg+PvV96X8AtdltE44ZvLrz4a+7z7V7qaum1c6A+pkuCO5ZCav+5vY74RJ3GwjB23/ujoXJVt3AXYXihguhv8M9XnlHdqHA9mddYLM+vOtXEKl22zPV2rIadzv/He6PhC1PcIDOHSMbjhYRkYIKHn4XiSZS/PZpVy3asv/gk63Lg+VUh6q5dfWtYOArr/4KIS/EvIb53L5vJe+eMonzonGunDiPf25uYv7KX/On6ioA3vfCbyjbu5b1U+oxwTBdniFuDI/2bOL9Pb38rb6JzeEQi2PZoa62ZbfSsPY+Vy3KBIKaae62YQ68+VvuF+4P0oHsnE+4s+NPPhWa57tqVv0s94t83b2DLwjfONcFotr0qUQylTRw88Le8n03t27RF2De21w1cNVfXVUt2uUWMCSjrirVeKybD/XgV9xQ5cnvcvfv+RxUNLj3ed/voSodAncvdZPo3/Q/cPLl7n0Bmo7Ltq9mCjSdwIxtt7tjffBPMG0hPPBlWP1Xd9z966F7F0w+Bc6/yg0dtm92w52Vja4a1r3TrVztb3dty3x3me+gelL2mK/6Z3eak+ohw7rhSvhiKyz9vVuxGa5231Vu9WtJeui5vz09rLnQPZ58Kqy/381Hm3SKC6AZlQ3wrhtcqDvrCnjbNfDN6dmFDxsehInz4bHvQdOJLoDtSA8VTznDreQ0Q/4OK0sHybkXQKgCVtwOx7w2+3zndjecfdl1cNJliIhI8aiSNgKrdnURS6QIB2DZjs6D7hfwAnzz/G9isVx+3OVMqXK/zOc3zqffJlgVCfO7mipWJDp4pKKcm7qy59S6sW8DL3hu6MkCSyMRbq+qIml93tXdwyzfsDEUZHnPNurTRY6dbel5VLlzt4bOC8uELHAh4PVXgxdwIQ2gbqYbYjPe4InkmXlWmfO91UyFqonufsOx7j2MgUWfdUOCVROzoWTz427+mReCWefCwo/Buf/PDZ1OOQNe82lXiXvu126u2YxXZQMawHtvhv9YA+de6d43c56yoXO/jr8Y3wThPTe5amAwAnPfBKvvcoHsZ2enP+MM1976mS649be7qmDNFNi93F1VANyKTYAJc7LHy3yfs17jKmvDfcfgjl0+wd0vq8l+V7nOTl/qqb/NtRPgdZ93Fa22jQPVwUGOWeTCtedBpCrbH+CuevCzs2H/Otev0xa6Pty+2H3v4BaSnPkRF6whW1kLV7jnVt3pFqFsf87NW9u93M0b3PDwgW0REZGXlULaCJw+o56nPv8GLpoVYu2ebvrjqYHnEimfu5btojvq5qqdP+187rnsHj6z8DMD+8yb4CpZQWvpN/DeR/8NgE7j0taxVdO4paaa26urCHpBAibA0+Vl3FxTzdmTzmJ20ueU7nZejERoT3RzYcCFgR396ZWW5AxNDRcOTnmPu80NF/Pf4apgU890ISYzrHj8xe52UnrIrzZdmaudmh3ubMypaA0cN6filOx3Z86fcY6rMoELGR99AC76hnv86ivdCsPunfCG/xz8XqHybJjwAtnKVdMJg/d73Rd4+pzrYO4bs9tOvMRVmnJPB5KZV1c/O3uC2ooG9330t7lh2bf/L8x8tXtu6hkw/51w/JtdpfE9v4P3/z77XdTkzEfLVV7vbiM1g4eGr3gEPrs5/TnT8wIzw5pTz4SLvuWeO2bR8O+bK/NZQpWuUnnCJfC6L7rb3CHRmemQVjsV3vpDF4whW0kDOOmdrop43evg+te76ub+de65rU8fvi0iIlJQCmkjVBkJMrvWw7ewfKerpsWSKS77+ZN88qbnueHxzQP7TqqcRDDnLPWza2dTFari9bEUl4QnDXpfY+GaC66jHMNDleWc3Hgy8xrmcVNtLfuCAT5+6iegejIXdXVi0ysLL2g6A4CdwUD2jS7/NXxqsQs1Q136U/j4o4MDXHm9q4IF0u087/+5+VFv+gr840NwzOvc9ub5MOcNMHtR9vXDhrT0c+lLYwHZk7JmVDdn50Q1zHHB4Y3/7cLcoWSqgU1DjhsIEY9MGLxt7gWuapS7mrV+VvY2s1AgM9wJ7jQap70vu3+4Ei7/lau8gQuw4crs6TaGDndmZEJaWY17/4yJ89xz4UpXdZx21uCgd/YV2RB1OHXpNr3py26+4GXXw2uvclXNaQvgnde5uXszXjX4da/9rOvXqWdmtx1/MZzzSVc9azwenvhRdgHC/nVuIciT1wy+FJiIiLxsNCftCMytC1AZDvCde9ZwyxXn8OT6/Szd7gLbC9sOvFzTc1vamNtcTU1ZiF9e+Euae9qpnzCHBbueoPm+/+afqmGmCTO1ehrXnvst1vRu46xjLqYv2ceXnvgSzRXNLJy0EComMK9rB9NT0BqOcNqCT1J7573sCAZhwhyuTe3lvnW/5mMV/8RFTcOcDiIQcnOfDmXK6XDVugO3R6rhQ3929+N9LmAcd+GB+2XmqzUe5yo3FQ3ZcHQwb/jSoZ/PmHCMm1uXWwU6mEi1C5jr7oXLb3TzsjIVsNz5XhWN2XPHTT1jZO2omwkzzxs8hyvXQEirzVbSyuogGM7uc/mNbmh0tI67wFW/Fn7MLQwZ6pR3u/8NZczggAYu0F/0DXjd1W6o+jvHupWj4Sp32o5Hvu3m0j3ybfjIXa66mkrCfV9089WmLxzVR4il3OrbzEKbUbHWreINlR1+XxGRo5RC2hGoChv+5+0n8e9/eInrHtvI1rY+KsMBLpg/iYdWt+L7lpsXb+WYpkraexN86ubnufzMaXzn8lOZ1zAP0os2L6u+DMLNzH3qak5ocsOKJ829mPnW8u171/D0xv28d+F3ec/C9NDWCZdgknH+bf77WEYZf9wQYbIpY3G55b+ajuPPHQkmxDq46tGrCHkh3jDzDazYt4I7NtzBZxZ+hoAJ0N6XYEKlCwu9sSSVkWzXx5M+4eAIiqrhCvjY/cM/l5lg33T8gWFgrN745fQpREbGnvFhTNsGOPaNbh5XxvRz3PnewhUuTFZPdpPnzx/hFRCCYfjI3w/+fHmdu80d7qxqHrzP0GrgkZr/jsHDmvmQ+Y6Oea070fCJb3UrZJdc574f68Pia90VFh77Hjzzc7dY5R3/605dMvGE7LD2CPzrQ1eS9BNcf+ENo2/z4mvditkrX3BBPCMRdSuGp56ZPaddvj3/Gzf/b+KJ7nG0y31PAf3nVETyS8OdR+idZ0zjgnnN/OD+tdy9bBevPb6Js2dPoLM/wQ8fXMcX/7Kc91/3DJ+62c19um/lHnpjSay1/PLxTVx5yws8tm4va8pO5WtvuIUvnP+tgff+5eOb+HnLBnZ1RLn69uVs3tcLwI+Sl3Fa21f5w+rX8OiSk/nC7cvY1D+ZzaEgf+9ez/tOeB+3v/XvzK2dxxef+CL7+/fzjcXf4JbVt/C3jX/jZy0bOPvrD7ByZxfXPbqR0//nfpZu78Bay/0r93DSf93L9Y+5k6Du7+3j03/9PZv3d7F6dxe+n53vZq3l4dWtbNjbQ1e8i68+/VVW7HNXI+gLVLM/Mp2N1YMD2qNr97K+teeA73F122q2dW87YDvAjp4dbOjYkN1Q1eRWWo7AbWtv480rf0LrR+8eHNAApp0JX2p188Oqm92q06t3ueHBfAiVu1/WZbXZk+UOM0dwY+fGg372fIulYizZvQQ7zCk14skk1y+5l65oH0/seILY3PRpXJpOyFbp5l4Ac9/ECxvvoffhr0HLN9xnXP8A/Ph0VvzmItrv/OTgN7YW4ydZf9/n2X3dIrjrM24V6bYl7HrhRp7Y+STP7F7C1qevGXyNWWvd5cj+8skDrz0LdMY6Wbb7OWhdTfeTP+ZJEyXV8k13zdXu3ZDoJ3rzu1nyu4uJv3QrD266j0dX3IyfORdcIgrr7s9eZQKwbZt5dulviW94EPu9E3n+jo/R/4OTePG2D9I33EmD19zjVvDe+gH3fs/8Ar5/ImuvfTV3v3g9e176nbvyhrWDP0Nf2+Druuba8Zz7foD2aDv3bLqHFftXDL/vkO954DQsw+nd777P/gOr/AB7+/by8fs/znN7nnPXco33uVXYv30ny5+7lt5EL6x7gKWr19DeG2f1mjvp7Nh8+HaNRNdO9m15jDU7noE9K+iIdrCmbc3hX/cyWr5vOZ2xgy8UG5HHvudORp35+etpHX76wPI/we8/BIkofYm+w/Z/wk/w4u5nsVueLtjpcta0reGBLQ/QcYg/kLd3b2d37+6DPr+/fz+bOzcXoHWHYa37N517zkxg5f6V9CeHuf6zte5k431tPLb9sUN+ppebGe4/3kebBQsW2GefffbwO45RS0sLixYtYndnlP9zwzNs3NvLzz5wBrMaK7ngB26F5WnT6/jA2TNIpCyhgOGq29xZ949pqmTj3l6qIkGSvo/vQ11FiKvfciL3rdhDyrfcv2oPbzqxma9cOp9F323huOZq3nnGVP7zjhWcNLWG5TvcubA+/abjuP6FvxCuXcaVp/07zRWT+NGD61izfyMVx/yAMn86/d5mAiZMwFYSaz8Tv2IpwXAHqf6pWBOnPjSTZGQZfuer6InHSUQbec2xE1nVex+9Zj2p3jngxWkoa6TGnkyZV0ck6PHMpjaMF6Vx2hP02h1UeA0kWy8lmvCJpeKU165lRl0TwXAHtaFmnlwVoaxuGTWhBo6pOoOTplbzzK6nWR99kIpAFZfO+Cd6+gOs6XyJSNBwcuPJ/GXrT0nYOOfVfwzPVjOltoyUbwkFPDwP+uM+sWSKSDjO5h3rOHHmaRgMKZvk95u/SzTVx0l153JW44UkbZytPWvY2reGU+rOwydFfbiZgBld1cPHpz22h7bYbprKphEOlBH2IgSNq1LW711Cf+VUohVTOO6Z/+Cv9ZNINZ/H8TULeKHtYTwCLO94ioAJctnMf6EskD3fmsXyYlsL0VQvCxsvYF3Xi3Qn2jil/nwAAiaAMR4mvfhgU89ydvRt4MyGN1IeqHTbjcEM7GF4cu9fWd25hFc1XcKJtWcN+ix3bbyX3f4TBKkmSTfzq8/gQ7tWsW3uB4mHJzBnxY/ZOfsytvSt5Y7exZwUi/Gu4PG0N7+KOSt+zMZwOT+qq2JGMsFl9W/BBssJpvqZuP0+OhMdfHtCLVV4fH7fXiLW4nthnogE+WNNJcbCW3t6WBCYTCpcRzAVxQ9WUL/vWTo8j9aa2TR6FTxVM4m22E7ekCznd6Eetqf28y9tHTxQWcGqSJhj43E+3NlNlYkQLW/mDm8/T5eXMSWZGpiz+dqozxuTFVTEOwkl3M9QLNJAb80cVvUs5fc11Zzb18/spM/vaiqZkrTsDBpOSnq8J9VAf9UM+qtn4yV7mbz5DloDUB3vJhysIRLvYHP9XK4JtZM0hgmpFP/a1kG1V471E9xT20CiYgpv3b2CUCpKT/Uc9k15HRP2PEGkfy9dE05mQutTBFJRts18OzcmVtCa6sCz8C89Po2RyXg2RdvEs/G9MMFEL2V9O/D8FOHYXqo61rJrxiXEy5oIJrtJBavwUlF2mASrO57ktO69vFg9kemVJ7AsuYtkrIfzak+nOTyZh3qf56XYRpop4wt7ttFbcyyJcB17ul7iZ/V1zDE1XLl7A3v8eh6pOJ6natYzLWV4R9OllEfbSAXKiIYqWdLzIpVeOSdVzBv4lxxMdONjWZzaRaRvF+f61TxaVUPUJjm77FimbPoTP6gOsC/g8em2Ln7TNI09fg/vq3k9EwN16aVQ7v83JHaxvW8dF0YtqYaFpEKuarsjsY+n+t3VOl5XcSoNgepD/uyG4l3U7n+B3pq5RCsmYdM/LxgPL9lP/d5n6a+cRl/1THYm2/h99yNMCU7g8urXDvxEZX9Wh1ZpD/w9Goh3sHH3ncSM4eSG1/OsF4X2F3hzdye9DWcQSMXoaDyTZ9pWE4iv4OLuLnonnstvQ51sSuzmndWvYUZwYs47Z+890reUF2PreVdXNyfUnEF3vftDc3+qixei6zmtbA4Tg/WH/D4yv/sHt9w92pvq5Nauh/CxTLYh5pgaIhUzODlyDD4+S6Jr8DA8H11PAMOHai+gzAsPeqeETXJz54N0+z18KtUMDWdhTZBV8a3sS3VyTtmJRNKvWRffwdbEHl5VPo9yc+A0iOFSSrxzN2V7lxKdeCrhGvfHcCjeSW3bi/hemFTncu6un8qsurOZFmpiY3wnd/Q8yUmpCG8rO4n+6tlE/TiL+5dzTPdO9ifaiAQqua/McO6EhVxe/UEWLVp0yO9wLIwxz1lrFxx2P4W0kcuEtAxrLcYYfN/ytbtWkUz5/OP5xzCt3v3ijSZSvPqbDxHwDN3RBGfNbuBbl53M2655gonVEXZ3RtnfG6emLEgiZZk+oZw/f/JcqiJB7nhxB1/6y3K6oklmNlRw15Wv4arbXmJDay9/u/I8nli/j6tuW8rebveXQlnI47jmatYmfkdowhOk+mYQ23shFVP/AMFOJgROZPf+Smpq9lERsbQltpCKTSQQacXgYXF/9dtkBXOqFrIx+gjV3nQ6o7144QMvBu8naqHzNZgJd2O87GpX45djTQw/VYkJ9GKMT9BWk6QPjNvP+kGSXacRqFyHF+pMf5cBsAbjJfETNVg/QiCy94DjHo71QyS7TiZU93xOP3nYRN2wn2O0rB/CeAe/+kRGIBkh6SUxXgqbKgeTxCZqwUsMfPah72v9MF6wF+sHsH4ZXrB3+DZYg03WDPs+uZK9xxKsXD/sc7X+GXTYlSR7jyNUs3TYfQDm9/usKgvgmyH/veifSnlkO/3egUOLFbEaegI+XnBIJbVvBkm/jGDVQS5AnyNgLbUpn7ZggIjvc3w8ydKyMJ6FE/fPpLtmA1vDOYHbQqBvOqnKbVy8t5ZtNLCicSP+IUY+a3ub6KzYCwZq+xrpLN9PdX8jfeWtpEY4ZBrsn8h32zfw9aZqWkPZ7ZW+jw/0eyMbtKjyfb7Vuo9raieyqnxELzmoickkrcHgwO2JsTgha1lalv0leElPL/dUVpAc8jlP7Y+zsixEImf7MVHDrnDqgM9Sk0oRNR7x4f4NpKuJfZ5Hme8TstAdcK+vTMGUZJJ1kSCVvs+sRIIVkQN/QRtraUqlaA0e+IfVmf1R+j3DymFeN1anRGOsC4dG3HfDCfuWoDX0BSBkLeW+pSsw+P08a6nxLR3p7SFrOSkW44WyQ8+3PLs/yjPlB+6T6e+xOiMa5R86uvjsxEaCFno9M/DvpDrlkzDQlEqRMIbdBzleXSpFQ8pnQzj7QxG0lhrfpy2QXeRmrKUh5bMvOMzCtzFoSibZm9O2M6JRXopEBv1cT0il6PA8wqkQiUCCk2NxPho/C07+mEJavhQrpI1ER1+cykiQ7miS6rIgoYBHdzRBeShAbyzFtvY+ZjZU4PsQDJhBc8W6ogm27u9jVmMlVZEg1loSKTswfyyaSA0MJTbXlFFfEaK1u4+k10lvbzV1FSHqKjw2tbdyYtM0dnVGmVJXjm99lmzbSIXXSMK0cfLk6ezo3sGm/V3MqJrJnIm17O7dTXNFMzs7+omym2iqn9auGBNrIgS9IHXBadRXlLOhbScp04nnufrN7Fo3OX9fd4ptHfupq+5nVt0MehO9rN+/k47eFKdPPQZjI2xta2dP/05qK4Kc3DyLfT0xVrZuprliGkETpI+dhAMe+3vjhAKGRMqSTPlEQgEqwgH6ogHWrVjPjBOy5w6rjzRRG65ne+8mkn6CgBeksWwSZYFy9vTvoCpYQ1usFd8eOJw2MoaGsiaqQ3W09ruVonE/RtIfPrBNrpxBLBWlLdrKpIrppGySSTWVJFM+q/ZtPGD/hrJmwl6YXX3bqI80UR6soLV/J0EvhG9Tg9pdFaqhJlTHrr5t+PhY62PJ/IVsB/ZpLJvEzr6txFPRQceqK6viNbPnsXlfDz2xFK39O+lNdB/QpoAXZHrFbNoTbXTG9me/CeMxo+oY+rs20NG1AWsCYAIkqiaxctVaLjjrLcRTsYHvyST7wXhMrJ5D0ARp7d+JTfZjbRIfA34CG6qkwgtT6Vva/H4a+9spq5zO1lQXk6LdlNfMYrPfS3W4ngnhBmysja2JNnw/SSDaTnnNMTSWNdMZb6cuvfK3P9lHa/+OA/o82N+KVzmdKZUzaYu10p/sY2rlLDrj7dSG6+nqWEWbZwn2t+HFu8B4JKqnU1M+iXgqSizVP/AX/rTKWYQTfSS8EK3xfURTbkhlcrAOkr3swv37MIk+Qr07SVY044erMYlejE3hhyoId26hKVxPZdUMohXNbOvdhLU+xk8QSg+P22AZiYrJrgKU/jzuOYsfrsGLd2ND5ZQn40yqmkNrWRUT4zHaE200EOaZ9fuYPi1JLNlDJFBGc/0ptPdtZ3+onGB0HybRR6pmNrMD1XR3b2JvRT2zKhP0trdSVncu0b6ddHSsIlnehJfsw0v0MrH2RJLJHtp7t6d/QsAPVwOGSSZMsnIqu2J7mJKIETJBdsZaSVQ201Q5iwrfsjmxlyn9nVQFytnavxML2TqVMVQHKqipmskmGyXYtWlgeK8iUMbksmastWyN7iRps38sDqp0ZX4hmwCJqmkDnxMsxvruezQe8ZoZBKIdePFuPDxmlk+hO9lDWyI9XJzzu3LY6D5MoK9tOA0vUM7+PU/QEKojUDOHHfG9mEQvNlRJqGc7rRt3cerCt7Al2UGocxMTglXUBavZFt1FKt3HZshxqgIVTKiaxdaAwXZuwKR/tsMmyJRIMztie4j58QPac0CTc9459zv3MEwrm0TABNhb0URFKkGiZyv7E27oc0pkIkmbImhcqNoZG3JJwLTmcANe1Qy2xvcR7tmOAepCNVQGKtge3Y1N/wTVBKuoD9WyLd3/w7d1sGC4nEkzj2P35tUkk+6zWhMiUTOTYH8rfsVkZtkg+7rX0ZeKEjQBppdPY3flBHo7N+DFuzAYppdNpqN6CpFwHbGe7dTFuqhvmMrqjTsU0vKllEOaFJb6pDSpX0qT+qX0qE9KU6H7ZaQhTQsHREREREqQQpqIiIhICVJIExERESlBCmkiIiIiJUghTURERKQEKaSJiIiIlCCFNBEREZESpJAmIiIiUoIU0kRERERKkEKaiIiISAkaF5eFMsbsBba8DIdqBPa9DMeRkVOflCb1S2lSv5Qe9UlpKnS/zLTWNh1up3ER0l4uxphnR3KtLXn5qE9Kk/qlNKlfSo/6pDSVSr9ouFNERESkBCmkiYiIiJQghbQjc22xGyAHUJ+UJvVLaVK/lB71SWkqiX7RnDQRERGREqRKmoiIiEgJUkgbAWPMRcaYNcaY9caYzxW7Pa8kxpgbjDGtxpjlOdsmGGPuN8asS9/Wp7cbY8yP0/201BhzRvFaPn4ZY6YbYx42xqwyxqwwxvxrerv6pYiMMWXGmMXGmJfS/fLl9PbZ5v+3d2+hUlVxHMe/v7TMMjJNI7SS0gcN6lggkgVmEd2oHpRumkTQSw8FRWUUgeBDD2UPRTt9NVsAAAVGSURBVAUVWdnVssKnSsvqQSsvXcgeSqJEyQdvWWRlvx72GptOck6gzt6d+X3gMLP+sxzXzJ+zz3+vvWaWtLrk5WVJR5T4kNL+pjw+rs7xD2SSBklaJ2lZaScnNZP0naQvJK2X9GmJNe4YliKtH5IGAY8ClwCTgGslTap3VF3lGeDiXrG7geW2JwDLSxuqHE0oPzcDj3VojN3mD+B22xOBqcAt5XcieanXHmCG7TOBHuBiSVOBB4CFJS/bgZtK/5uA7bbHAwtLvzg0bgU2tLWTk2Y433ZP21dtNO4YliKtf1OAb2xvtP0b8BJwZc1j6hq2PwC29QpfCSwq9xcBV7XFn3VlFTBc0omdGWn3sL3F9tpy/yeqPz5jSF5qVd7f3aV5ePkxMANYUuK989LK1xLgAknq0HC7hqSxwGXAk6UtkpOmatwxLEVa/8YAP7S1N5VY1OcE21ugKhiA0SWeXHVYuRwzGVhN8lK7clltPbAVeAf4Fthh+4/Spf2935eX8vhOYGRnR9wVHgbuBP4s7ZEkJ01g4G1JayTdXGKNO4YN7sR/8j+3v7OYfCS2mZKrDpI0DHgNuM32rj5O+JOXDrG9F+iRNBxYCkzcX7dym7wcYpIuB7baXiNpeiu8n67JSedNs71Z0mjgHUlf99G3trxkJq1/m4CT2tpjgc01jSUqP7ammsvt1hJPrjpE0uFUBdpi26+XcPLSELZ3AO9TrRkcLql1Qt7+3u/LS3n8WP69tCAOzDTgCknfUS2VmUE1s5ac1Mz25nK7leqEZgoNPIalSOvfJ8CE8mmcI4BrgLdqHlO3ewuYW+7PBd5si99QPokzFdjZmrqOg6eskXkK2GD7obaHkpcaSRpVZtCQNBS4kGq94HvAzNKtd15a+ZoJrHC+OPOgsj3P9ljb46j+dqywfT3JSa0kHS3pmNZ94CLgSxp4DMuX2f4Hki6lOvsZBDxte0HNQ+oakl4EpgPHAz8C9wNvAK8AJwPfA7NsbyvFwyNUnwb9BbjR9qd1jHsgk3Qu8CHwBX+vs7mHal1a8lITSWdQLXYeRHUC/ort+ZJOpZrFGQGsA2bb3iPpSOA5qjWF24BrbG+sZ/QDX7nceYfty5OTepX3f2lpDgZesL1A0kgadgxLkRYRERHRQLncGREREdFAKdIiIiIiGihFWkREREQDpUiLiIiIaKAUaRERERENlCItIuIASJouaVnd44iIgSdFWkREREQDpUiLiK4gabakjyWtl/RE2Yx8t6QHJa2VtFzSqNK3R9IqSZ9LWirpuBIfL+ldSZ+Vf3NaefphkpZI+lrSYvWxkWlExH+VIi0iBjxJE4GrqTZV7gH2AtcDRwNrbZ8FrKTa0QLgWeAu22dQ7azQii8GHrV9JnAO0NoaZjJwGzAJOJVqz8aIiAMyuP8uERH/excAZwOflEmuoVSbJ/8JvFz6PA+8LulYYLjtlSW+CHi17PU3xvZSANu/ApTn+9j2ptJeD4wDPjr0LysiBrIUaRHRDQQssj3vH0Hpvl79+tonr69LmHva7u8lx9aIOAhyuTMiusFyYKak0QCSRkg6heoYOLP0uQ74yPZOYLuk80p8DrDS9i5gk6SrynMMkXRUR19FRHSVnO1FxIBn+ytJ9wJvSzoM+B24BfgZOF3SGmAn1bo1gLnA46UI2wjcWOJzgCckzS/PMauDLyMiuozsvmb3IyIGLkm7bQ+rexwREfuTy50RERERDZSZtIiIiIgGykxaRERERAOlSIuIiIhooBRpEREREQ2UIi0iIiKigVKkRURERDRQirSIiIiIBvoLLPPWJXGMvAEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in hist_list[0].keys() :\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.grid(True)\n",
    "    plt.title('model ' + key)\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel('epoch')\n",
    "    for hist in hist_list :\n",
    "        plt.plot(hist[key])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 1s 3ms/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1429 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3431 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3272 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3403 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1555 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1806 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2414 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1426 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3407 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3407 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1435 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3324 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1441 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1446 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1452 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3411 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1459 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3412 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1465 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2443 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1484 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2455 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2458 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1504 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 0s 3ms/step - loss: -14.0138 - acc: 0.2812 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2481 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.0980 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2945 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2770 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3100 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1418 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.1420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3019 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2907 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3308 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2471 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3242 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1429 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3407 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1434 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2435 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1439 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2486 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3184 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3410 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2431 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2432 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3411 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2435 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3384 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1463 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 1s 3ms/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1690 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2261 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.2378 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3315 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1489 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2274 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3164 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3296 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2417 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3315 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3407 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.0416 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3410 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1451 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1458 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2441 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2444 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.1478 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.1485 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2452 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2457 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2457 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2461 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2464 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 25us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 50us/step - loss: -15.2466 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2468 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3421 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 2.9808 - acc: 0.1812 - val_loss: -10.4938 - val_acc: 0.3333\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -10.8886 - acc: 0.2875 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -12.8072 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -13.9445 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.0240 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.0388 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.1233 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3171 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -14.9110 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.1143 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.2046 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3108 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 150us/step - loss: -15.1994 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.2711 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2260 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2641 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2933 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.2041 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.2126 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.2309 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.2932 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3285 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3202 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2898 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2623 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3123 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.2418 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3008 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3324 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3110 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3181 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -14.9358 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3143 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.1349 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.1312 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2671 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3216 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2041 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3209 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2922 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.0651 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3216 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2779 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2928 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2912 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 150us/step - loss: -15.3308 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3100 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.2792 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3078 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3054 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3100 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3179 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3110 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2828 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3272 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3111 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2815 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3274 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3077 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3102 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2392 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2901 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2785 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3285 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3333 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2467 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2905 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.1137 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3345 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.1773 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2803 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2884 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.2980 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3158 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 225us/step - loss: -15.2951 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3221 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3403 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3170 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2791 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.2528 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2771 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 250us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3377 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2328 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 200us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 175us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3065 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3255 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9780 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.2763 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3272 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3181 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2815 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2908 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2883 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3054 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3154 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1959 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Train on 160 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "160/160 [==============================] - 1s 8ms/step - loss: -15.1232 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 2/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.3580 - acc: 0.3250 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 3/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.4117 - acc: 0.3125 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 4/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.6503 - acc: 0.3188 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 5/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.7451 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 6/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.9570 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 7/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.8766 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 8/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.8062 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 9/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0822 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 10/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.8596 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 11/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2620 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 12/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2832 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 13/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1354 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 14/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.6131 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.3161 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 16/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.8483 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 17/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9021 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 18/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.8926 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 19/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0477 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 20/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.8629 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 21/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1537 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 22/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2744 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 23/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3066 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 24/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2384 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3212 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2225 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2424 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2425 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3365 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3359 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.1369 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1363 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 37/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3265 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 38/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3233 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 39/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1316 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 40/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3409 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 41/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2235 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 42/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3066 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 43/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 44/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2429 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 45/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2430 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 46/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1272 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 47/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 48/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 49/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2432 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 50/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0440 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 51/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0312 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 52/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1456 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 53/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9471 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 54/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3412 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 55/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2436 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 56/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3378 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 57/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3412 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.4474 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 59/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2406 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 60/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 61/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3413 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2441 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.7464 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3414 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1473 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1369 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.7509 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2446 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3415 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2447 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2448 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2418 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -14.9429 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2480 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.0490 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.9390 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.9627 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1461 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -14.9225 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3330 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3190 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3184 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1500 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3221 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3418 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3272 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 93/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3419 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1507 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3285 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2465 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3420 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2466 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1513 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 118/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 125/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2444 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 129/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3421 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 130/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 131/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3421 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3421 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1520 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2471 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 148/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 149/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 150/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.2473 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 152/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 153/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 154/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 155/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1526 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 156/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 157/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 158/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 159/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 160/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 161/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 162/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3422 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 163/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 164/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 165/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 166/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 167/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 168/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2476 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 169/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 170/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 171/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2477 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 172/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 173/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 174/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 175/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1532 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 176/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 177/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 178/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 179/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 180/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 181/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 182/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2479 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 183/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 184/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1536 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 185/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 186/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 187/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 188/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2459 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 189/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 190/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 191/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 192/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 193/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 194/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 195/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2461 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 196/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2483 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 197/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 198/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 199/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 200/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1544 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 201/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2485 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 202/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 203/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1548 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 204/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 205/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 206/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 207/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2488 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 208/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 209/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.2926 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 210/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 211/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 212/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 213/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 214/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3426 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 215/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 216/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 217/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 218/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 219/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 220/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 221/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 222/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 223/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 224/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 225/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 226/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2491 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 227/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 228/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 229/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 230/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 231/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 232/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 233/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 234/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 235/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.1557 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 236/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 237/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 238/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 239/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3426 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 240/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 241/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 242/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 243/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 244/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 245/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 246/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 247/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 248/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 249/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 250/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 251/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 252/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 253/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 254/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 255/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 256/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 257/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 258/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 259/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 260/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 261/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 262/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 263/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 264/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 265/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 266/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 268/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 269/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 270/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 271/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 272/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 273/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 274/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 275/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 276/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 277/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 278/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 279/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 280/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 281/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 282/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1560 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 283/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 284/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 285/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 286/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 287/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 288/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 289/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 290/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 291/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 292/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 293/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 294/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 295/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 296/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 297/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 298/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 299/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 300/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 301/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 302/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 303/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 304/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 305/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 306/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 307/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 308/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 309/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 310/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 311/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 312/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 313/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 314/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 315/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 316/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 317/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 318/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 319/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 320/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 321/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 322/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 323/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 324/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 326/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 327/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 328/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 329/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 330/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 331/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 332/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 333/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 334/500\n",
      "160/160 [==============================] - 0s 150us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 335/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.2495 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 336/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 337/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 338/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1566 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 339/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3427 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 340/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 341/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 342/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 343/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 344/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 345/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 346/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 347/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 348/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 349/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 350/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 351/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 352/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 353/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 354/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 355/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 356/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 357/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 358/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 359/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 360/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 361/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 362/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 363/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 364/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 365/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 366/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 367/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.2499 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 368/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 369/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 370/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 371/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 372/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 373/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 374/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3428 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 375/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 376/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 377/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.1573 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 378/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 379/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 380/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 381/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 382/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 384/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 385/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 386/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 387/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3428 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 388/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 389/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3428 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 390/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 391/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 392/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 393/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 394/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 395/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 396/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 397/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 398/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 399/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.2503 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 400/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 401/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 402/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 403/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 404/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 405/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 406/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3428 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 407/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 408/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 409/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3428 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 410/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 411/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 412/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 413/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 414/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 415/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 416/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 417/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 418/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 419/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 420/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 421/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 422/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 423/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 424/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 425/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 426/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3402 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 427/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 428/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 429/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 430/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 431/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 432/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 433/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 434/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 435/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 436/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 437/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 438/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 439/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 440/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 442/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 443/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 444/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 445/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 446/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 447/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 448/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 449/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 450/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 451/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 452/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 453/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 454/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 455/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 456/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 457/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 458/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 459/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 460/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 461/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 462/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 463/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 464/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 465/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 466/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 467/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.1585 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 468/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 469/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 470/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 471/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 472/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 473/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 474/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 475/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 476/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 477/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 478/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 479/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 480/500\n",
      "160/160 [==============================] - 0s 125us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 481/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 482/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 483/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 484/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 485/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 486/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 487/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 488/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 489/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 490/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 491/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 492/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 493/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 494/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 495/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 496/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 497/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 498/500\n",
      "160/160 [==============================] - 0s 100us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n",
      "Epoch 500/500\n",
      "160/160 [==============================] - 0s 75us/step - loss: -15.3445 - acc: 0.3312 - val_loss: -11.5139 - val_acc: 0.3333\n"
     ]
    }
   ],
   "source": [
    "hist_list = []\n",
    "\n",
    "for noise_koef in np.linspace(0,1,num=5) :\n",
    "    noise = np.random.normal(loc=0.5,scale=0.16,size=x_train.shape)\n",
    "    x_part_noise = x_train + noise_koef * noise\n",
    "    model = Sequential()\n",
    "    hist = neural_net (model)\n",
    "    hist_list.append(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAFNCAYAAABfUShSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X+cXXV95/HXZ2bygyRAAiQjJBGwghIVQcf4q5pR2RbWFmprt9BisQ/d6CrVPmzt0mKxpfp4tLi1bre0Jbul9UctRSoubUORpQzqrsgP+WXAlIhAIkr4kYDDjyQz97N/3DPDzTBJ7oGcc08yr+fjkUfuOed77vnO/Uwm7/me7zknMhNJkiQ1U1+vOyBJkqRdM6xJkiQ1mGFNkiSpwQxrkiRJDWZYkyRJajDDmiRJUoMZ1iT1XET8bUR8osu290bESc/zeFdGxFl7oz/Psx9vioj1VR9H0r5toNcdkKS6ZeYpE68j4t3AezPzJ3vQj68DL6n7uJL2LY6sSZIkNZhhTVJXitOPH42I2yPiiYj464gYLE4p/jgi/k9ELOpof2pErIuIrRExEhHHdWw7MSK+Xez3D8DcKcf6mYi4tdj3/0XE8V307+iifV+x/L8iYnPH9i9ExG8Ur0ci4r1Fn/4KeH1EjEbE1o63XBQR/1L08VsR8RO7OO5REZERcVZE3B8RD0fEuR3b50TEZyLigeLPZyJiTrFtOCI2dbT9rxHxg+KY6yPibcX6vog4JyK+FxGPRMSlEXHILvqzKCL+OSIeiogtxetlHdsPiYi/KfqyJSK+0rHttOJzf7w41sl7+twlVc+wJqmMXwD+A3As8LPAlcDvAofR/nnyIYCIOBb4e+A3gMXAWuCfImJ2RMwGvgJ8HjgE+FLxvhT7vgq4GHgfcChwEXDFRMDZlcz8PvA4cGKx6k3AaEdIfDNw3ZR97gLeD3wzMxdk5sKOzWcAfwAsAjYAn9zDZ/OTtE9pvg04r+O45wKvA04AXgmsBD42deeIeAlwNvCazDwQ+Gng3mLzh4CfA1YBRwBbgAt30Y8+4G+AI4EXAk8Bf96x/fPAPOBlwBLgT4vjrwQ+B3wUWEj787oXST1nWJNUxv/IzAcz8wfA14FvZeYtmbkNuJxngtIvAf+SmVdn5g7gvwEHAG+gHVxmAZ/JzB2ZeRlwY8cx/jNwUWZ+KzPHM/OzwLZivz25DlgVES8oli8rlo8GDgJuK/G1fjkzb8jMMeDvaIet3fmDzHwqM28rjvPKYv2vAOdn5ubMfIh2AHzXNPuPA3OAFRExKzPvzczvFdveB5ybmZuKz/r3gXdGxLPmHWfmI5n5j5n5ZGb+mHbIXAUQEYcDpwDvz8wtxec/EWDfA1xc1KyVmT/IzO928TlJqphhTVIZD3a8fmqa5QXF6yOA+yY2ZGYL2AgsLbb9IDOzY9/7Ol4fCfxmcUpza3Fqcnmx355cBwzTHhX6GjBCO6isAr5e9KNbP+p4/STPfG1l2+/0WRSvn/W1ZOYG2iORvw9sjohLImKi3ZHA5R2fx120w93g1PeJiHkRcVFE3BcRj9P+HBZGRD/tz/HRzNwyTf+XA9+bZr2kHjOsSarCA7QDBgAREbTDwA+AHwJLi3UTXtjxeiPwycxc2PFnXmb+fRfHvY726c/h4vU3gDfSDmvX7WKf3MX6vWWnz4L21/rAtB3J/GJxVeqRRb/+uNi0EThlymcytxjhnOo3aZ+OfW1mHkQ7uAJE8T6HRMTCafbbCEw7L09SbxnWJFXhUuDtEfG2iJhFO0BsA/4f8E1gDPhQRAxExM/Tnsc14X8C74+I10bb/Ih4e0QcuKeDZubdtEf4zgS+lpmP0x79+wV2HdYeBJYVc+mq8PfAxyJicUQcBpwHfGFqo4h4SUS8tZib9zTtr2O82PxXwCcj4sii7eKIOG0Xxzuw2HdrcRHCxyc2ZOYPac8z/IviQoRZETER5v4a+LWiZn0RsTQiXvp8v3hJz59hTdJel5nraQem/wE8TPtihJ/NzO2ZuR34eeDdtCfK/xLw5Y59b6I9b+3Pi+0birbdug54JDPv71gO4JZdtP83YB3wo4h4uMRxuvUJ4CbgduAO4NvFuqnmAH9E+/P6Ee3J/79bbPvvwBXAVyPix8D1wGt3cbzP0J4f+HDR7l+nbH8XsAP4LrCZ9qlXMvMG4NdoX3DwGO3P7Ugk9VzsPG1EkiRJTeLImiRJUoMZ1iRJkhrMsCZJktRghjVJkqQGM6xJkiQ12LMeVbKvOuyww/Koo46q/DhPPPEE8+fPr/w46p41aSbr0kzWpXmsSTNVXZebb7754cxc3E3b/SasHXXUUdx0002VH2dkZITh4eHKj6PuWZNmsi7NZF2ax5o0U9V1iYj79tyqzdOgkiRJDWZYkyRJajDDmiRJUoMZ1iRJkhrMsCZJktRghjVJkqQGM6xJkiQ1mGFNkiSpwQxrkiRJDRaZ2es+7BVDQ0NZ9RMM3nHJb/Pw47dwzMNP8fj8Pga3vID+PIK525NFj49XemxNFeyIWczK7ZAJEbts2eqDjYOzGHxkjLnbn/l+z4AfLJnFosfHmf9Uq6ujPnjoALPHkkWPPbve4wxAQH+Olf9y9kd7qMtM0aKPVvQzkDt63ZW2LuoyHgOQ0I/fy7vz2II+njygj8Mfep6fk/9WGmf2nH5efeo7qn6Cwc2ZOdRN2/3mcVN1ObK1iY9+Dnb0Jze85gNsm7uk113SnozDwk3Tbzr4gXJvddDm598dSfuHgx4DHut1L1SFuY/+sNdd2IlhrYTLT7+AsT/8AndzMLPGg/H++Szfvp4X3nEJB731Jznk9F/odRdnhkfuhn/9XXjh6+H+b3LXcR/huFe9ftqmuWOM+977Iea95kSevPEWBj/66xzw8uMAuO+//BYHvPylPHnDtzn0vb/KgW963W4P+6M//jPIZNv9G1nw+pUc+q7/9MzG6/8CHvwOzD4I5h0Cq357r325+6rb7vgOr3zFy3vdjd767lq4+W/a36uPboDT/qLXPdpzXUb+CLY9Bk9ugSNOgNe+v77O7UO2XnElW//xnzhg6ETGNm9m6R+e+5zfy38rzdM3Z5Bvb36o192YZFgrrX36K4Hx/rkMPLKZOT/ezMHHvoiFJ76qt12bKbYcCt94GLbfCAc+yrYXvXS3n/3m2ePEv69jzvbHWLRyiLkveQkAjyyaS2v9d9rrTzyeBXuo3xPLFvPEt65n9paHOfjYo3c+5iPL4KHLof8g+InTwO8F8rHH/Tcx6/uwvvheXbqsEd8Xe6zL/Utg/c3Q/ygce2oj+txE+e8beGr7Y/TdvY4Djz32eX2v+2+loTaP9LoHk7zAoKTI9tymjAGyr5/48RYABpZ4OrQ2B76g/ffoj2DBIET/bpsPLFnC2EMPTb6efv3iPR52YMkSxh96uP168ZT2Bx4OrTF46tH2awme+V4Y/dEz37dNd+Dh8OTDkK19p889MPEzY+yhh/z5r8oZ1kqaCGtjA3MA6B9/GpjmP29VZ2AOHLCo/XrB4J6bT9Rm1iz6Fy589nq6q99O7aeGu85+HLjnPmmG2On7Yh8JPp3fvwv2kT73wMDijl/8/PmvihnWSpoIa+P9cwEYGN/W/tt/rPWa+E+ki/8AJ2ozcNhhRMcVV7sKcXt6H5hmJLWzH/4Hpwn74vdFZz/3lYDZA2V/2ZOeD8NaGZkEE2FtYmTNsNYTE7/9lxhZm1qjnUJc357/Kez2h7Mja5rO7Pkw+8D2633l+2KngLmP9LkHBg49ZPJ2G/78V9UMa2Vki4nb0k2GtbGniblz6TvwwB52bAaamAvUxfywiVGwqacuJ9d3+YN2cv+BgWePxHX+B+ecNXWa+N7YV74vDGtdiYEB+g87FHDOsqpnWCujNd6+DBQYK06D9o9vY2Dx4p1Or6kGE/+JdDFasceRtS4uLmi3fybcPWskbtYBMPdgiD6Y72/Z6jARfvaV4DO/CB7zDoWB2b3tS8OV/RkiPVeGtTJyfDKvTYysDcSYQ+C9MPkfYIk5a7sKa13Wr3/BfGLevF23X/CCdlDr2/3VqZphJn+x2Efmfw3Mbge1fWWOXQ+V/RkiPVfeZ62M1jiXbf0TDl5+O7N3/BiAOYcdzKwjjuhxx2agg5e3/164HH70yG6bzlrars/UOg0sWQL9/aXqN+uIw3fdfuFyeMrT4Zpi4XIYOADmHdbrnnTv4OX7TrjsoVlHHEH/oYfSN2dOr7ui/ZxhrYwcZ8v4UgbmPcj8F70UnoLln/gDFrxgz1cSai97ySlw5j/CC14B3x3ZbdPZy5bxwr+5mANe/eqd1vcvmM+Rn/ssc449tuvDLv30p+lfsGD6jf/xv8F4Q57/qOZ4w4fgpT8DXVzE0hg/v6Z9ixzt1uIPfICF73xnr7uhGcCwVkJrxxjjzGF8YC4sOQLugwNffiwDszztVbu+fnjxSV03n//66R9HNW9KgNuTubsLdoccXeq9NEPMO6T9Z1+y+CW97sE+YWDxYk+Bqhb70K96vbfj6faoyXj/HMZa/fT1Bf0DfoSSJKk6Jo0Stu8U1vqYNbffq0AlSVKlKg1rEXFyRKyPiA0Rcc40298fEXdExK0R8Y2IWFGs/w8RcXOx7eaIeGuV/ezWjqfaYW2sfy5j2cesOZ7+lCRJ1aosrEVEP3AhcAqwAjhjIox1+GJmviIzTwAuAD5drH8Y+NnMfAVwFvD5qvpZxo5tY0B7ZG3HuGFNkiRVr8qRtZXAhsy8JzO3A5cAp3U2yMzHOxbnU9xyNjNvycwHivXrgLkR0fNLk7Y/9UxYGxsPZs31+gxJklStKtPGUmBjx/Im4LVTG0XEB4GPALOB6U53/gJwS2Zuq6KTZezYNg7A+MBcxsb7mDPXkTVJklStyImHXe7tN474ReCnM/O9xfK7gJWZ+eu7aP/LRfuzOta9DLgC+KnM/N40+6wGVgMMDg6++pJLLtn7X0iHJ9c/zPdvaV+CP2fW08xeMpcXvslrNHptdHSUBbu695l6xro0k3VpHmvSTFXX5S1vecvNmTnUTdsqR9Y2Acs7lpcBD+yiLbRPk/7lxEJELAMuB351uqAGkJlrgDUAQ0NDOTw8/Dy7vHvf+fFNfP+W9pnbFnM4fNkgw8Mvq/SY2rORkRGqrr3Ksy7NZF2ax5o0U5PqUuWw0I3AMRFxdETMBk6nPUo2KSKO6Vh8O3B3sX4h8C/A72Tm/62wj6VsL06DAuzYEcydP6uHvZEkSTNBZWEtM8eAs4GrgLuASzNzXUScHxGnFs3Ojoh1EXEr7XlrE6dAzwZeDPxecVuPWyNiSVV97daOjrAGMP/gnl/zIEmS9nOVXs6YmWuBtVPWndfx+sO72O8TwCeq7NtzsWN7a6fleQfP7lFPJEnSTOHs+BK2P73zxRiOrEmSpKoZ1kpwZE2SJNXNsFbCju0tZuUTk8uOrEmSpKoZ1krYsS2Zx1YA+vthzjyfYCBJkqplWCth+3Y4gC0AHDCvj4jocY8kSdL+zrBWwo7tyZx8HLLFvAU+akqSJFXPsFbCjh0wi6foH9/GvPmeApUkSdUzrJUwPgazWk+zaOvdHH7kAb3ujiRJmgEMayW8931P8KqxL3L8dy7i5a9Z2OvuSJKkGcCwVkaOQxY3xh3wNKgkSaqeYa2M1ji02leARp8fnSRJqp6Jo4xsTQ6s0e/ImiRJqp5hrYzW+GRYiwFv3SFJkqpnWCsjxyGLG+F6GlSSJNXAxFFGa6xjZM3ToJIkqXqGtTJa49Bqv4x+T4NKkqTqGdbKyBY5cRrUsCZJkmpgWCujNQ4Tp0ENa5IkqQaGtTJynGw5siZJkupjWCtj4tYdfX1ERK97I0mSZgDDWhmtMUhPgUqSpPoY1srI8fYFBoY1SZJUE8NaGa2WI2uSJKlWhrUycpxs4ciaJEmqTaVhLSJOjoj1EbEhIs6ZZvv7I+KOiLg1Ir4RESs6tv1Osd/6iPjpKvvZtVb7NKgja5IkqS6VhbWI6AcuBE4BVgBndIaxwhcz8xWZeQJwAfDpYt8VwOnAy4CTgb8o3q+3cpzMPvAh7pIkqSZVjqytBDZk5j2ZuR24BDits0FmPt6xOJ/JW85yGnBJZm7LzO8DG4r3663WWHtkrc+wJkmS6lHl08iXAhs7ljcBr53aKCI+CHwEmA28tWPf66fsu7SabpbQapF4GlSSJNWnyrA23V1j81krMi8ELoyIXwY+BpzV7b4RsRpYDTA4OMjIyMjz6e8evXjjfWQreGr79sqPpe6Njo5ajwayLs1kXZrHmjRTk+pSZVjbBCzvWF4GPLCb9pcAf1lm38xcA6wBGBoayuHh4efR3S488c9szGDeggW8oupjqWsjIyNUXnuVZl2aybo0jzVppibVpco5azcCx0TE0RExm/YFA1d0NoiIYzoW3w7cXby+Ajg9IuZExNHAMcANFfa1OxM3xfUCA0mSVJPKRtYycywizgauAvqBizNzXUScD9yUmVcAZ0fEScAOYAvtU6AU7S4F7gTGgA9m5nhVfe3axK07vMBAkiTVpMrToGTmWmDtlHXndbz+8G72/STwyep69xy0xtsz5xxZkyRJNfEJBmWkI2uSJKlehrUyfIKBJEmqmWGtjByHDBio9OyxJEnSJMNaGa1xMiH6/NgkSVI9TB1leOsOSZJUM8NaGa1xaOEFBpIkqTaGtTKK06COrEmSpLoY1sooLjCIfi8wkCRJ9TCsldEaJ1sQ/X5skiSpHqaOMrJ4goEja5IkqSaGtTJarfatO7wpriRJqolhrYzWGLQAT4NKkqSamDrKyOKmuJ4GlSRJNTGsldGamLPmxyZJkuph6igji5viOrImSZJqYlgrY/ICAz82SZJUD1NHGRO37gg/NkmSVA9TRxmtsfbfEb3thyRJmjEMa2VMXGDQZ1iTJEn1MKyVMXHrDkfWJElSTQxrZbRaQDpnTZIk1cbUUcbkBQaOrEmSpHoY1spojbf/ds6aJEmqiWGtjNZY+yyoI2uSJKkmlYa1iDg5ItZHxIaIOGea7R+JiDsj4vaIuCYijuzYdkFErIuIuyLiz6IJCSmLkTXnrEmSpJpUljoioh+4EDgFWAGcERErpjS7BRjKzOOBy4ALin3fALwROB54OfAaYFVVfe1aq0VxOWiveyJJkmaIKoeIVgIbMvOezNwOXAKc1tkgM6/NzCeLxeuBZRObgLnAbGAOMAt4sMK+dmf4HJJwzpokSapNlWFtKbCxY3lTsW5X3gNcCZCZ3wSuBX5Y/LkqM++qqJ/de/0HvBpUkiTVaqDC954u0eS0DSPOBIYoTnVGxIuB43hmpO3qiHhzZn5tyn6rgdUAg4ODjIyM7J2e78ZgJvfdfz931nAsdWd0dLSW2qsc69JM1qV5rEkzNakuVYa1TcDyjuVlwANTG0XEScC5wKrM3FasfgdwfWaOFm2uBF4H7BTWMnMNsAZgaGgoh4eH9/KXsLPM5LvAUUcdzeKKj6XujYyMUHXtVZ51aSbr0jzWpJmaVJcqT4PeCBwTEUdHxGzgdOCKzgYRcSJwEXBqZm7u2HQ/sCoiBiJiFu0Rt96fBs1iYNA5a5IkqSaVhbXMHAPOBq6iHbQuzcx1EXF+RJxaNPsUsAD4UkTcGhETYe4y4HvAHcBtwG2Z+U9V9bVrrVb7b+esSZKkmlR5GpTMXAusnbLuvI7XJ+1iv3HgfVX27TkpRtaiz/usSZKkepg6SsiJ06DTXjshSZK09xnWypics+bHJkmS6mHqKGNyzlpvuyFJkmYOw1oZzlmTJEk1M3WUkC3nrEmSpHoZ1kpxzpokSaqXqaMM56xJkqSaGdbKcM6aJEmqmamjhJwYWXNoTZIk1cSw9lw4siZJkmpi6ijDOWuSJKlmhrUynLMmSZJqZuooYXLOWji0JkmS6mFYK2Pynrh+bJIkqR6mjjLSOWuSJKlehrUynLMmSZJqZuoowzlrkiSpZoa1EtI5a5IkqWamjjLSkTVJklQvw1oZk3PWDGuSJKkehrUynLMmSZJqZlgrIScmrRnWJElSTQxrZUyGNT82SZJUD1NHGZNhrbfdkCRJM0elYS0iTo6I9RGxISLOmWb7RyLizoi4PSKuiYgjO7a9MCK+GhF3FW2OqrKvXfGmuJIkqWaVpY6I6AcuBE4BVgBnRMSKKc1uAYYy83jgMuCCjm2fAz6VmccBK4HNVfW1Wz7IXZIk1a3KIaKVwIbMvCcztwOXAKd1NsjMazPzyWLxemAZQBHqBjLz6qLdaEe73vGmuJIkqWZVpo6lwMaO5U3Ful15D3Bl8fpYYGtEfDkibomITxUjdb3lg9wlSVLNBrppFBHvAP4tMx8rlhcCw5n5ld3tNs26nGYdEXEmMASs6ujXm4ATgfuBfwDeDfz1lP1WA6sBBgcHGRkZ6ebLec4GNm7kUGDdnXeybfbsSo+l7o2OjlZee5VnXZrJujSPNWmmJtWlq7AGfDwzL59YyMytEfFxYHdhbROwvGN5GfDA1EYRcRJwLrAqM7d17HtLZt5TtPkK8DqmhLXMXAOsARgaGsrh4eEuv5zn5ql167gXePkrXsGBFR9L3RsZGaHq2qs869JM1qV5rEkzNaku3Z4Gna7dnoLejcAxEXF0RMwGTgeu6GwQEScCFwGnZubmKfsuiojFxfJbgTu77Gt1nLMmSZJq1m3quCkiPh0RPxERL4qIPwVu3t0OmTkGnA1cBdwFXJqZ6yLi/Ig4tWj2KWAB8KWIuDUirij2HQd+C7gmIu6gfUr1f5b+6vY256xJkqSadXsa9NeB36M9dwzgq8DH9rRTZq4F1k5Zd17H65N2s+/VwPFd9q8e3mdNkiTVrKuwlplPAM+6qe2M433WJElSzboaIoqIq4srQCeWF0XEVdV1q5nSZ4NKkqSadZs6DsvMrRMLmbkFWFJNlxpsMqw5siZJkurRbVhrRcQLJxaK53ROe8+0/drknDXDmiRJqke3FxicC3wjIq4rlt9McTPaGcU5a5IkqWbdXmDwrxExRDug3Qr8b+CpKjvWRM5ZkyRJdev2cVPvBT5M+ykEt9J+msA3ad+sduZoOWdNkiTVq9shog8DrwHuy8y30H5m50OV9aqxnLMmSZLq1W1YezoznwaIiDmZ+V3gJdV1q6GcsyZJkmrW7QUGm4r7rH0FuDoitjDNQ9n3d5Nz1nyCgSRJqkm3Fxi8o3j5+xFxLXAw8K+V9aqpWpNPcu9pNyRJ0szR7cjapMy8bs+t9lfOWZMkSfXyfF4ZzlmTJEk1M6yV4Jw1SZJUN1NHGc5ZkyRJNTOslTIxsmZYkyRJ9TCslVHMWQvnrEmSpJoY1kpwzpokSaqbqaMMnw0qSZJqZlgrIw1rkiSpXoa1MtI5a5IkqV6GtTKcsyZJkmpm6ighnbMmSZJqZlgrwzlrkiSpZpWGtYg4OSLWR8SGiDhnmu0fiYg7I+L2iLgmIo6csv2giPhBRPx5lf3smnPWJElSzSoLaxHRD1wInAKsAM6IiBVTmt0CDGXm8cBlwAVTtv8hcF1VfSzNOWuSJKlmVaaOlcCGzLwnM7cDlwCndTbIzGsz88li8Xpg2cS2iHg1MAh8tcI+luKcNUmSVLcqw9pSYGPH8qZi3a68B7gSICL6gD8BPlpZ756LyTlrjqxJkqR6DFT43tMNP+W0DSPOBIaAVcWqDwBrM3Pj7uaHRcRqYDXA4OAgIyMjz6e/ezT3rrs4GLj+W9fT2nBopcdS90ZHRyuvvcqzLs1kXZrHmjRTk+pSZVjbBCzvWF4GPDC1UUScBJwLrMrMbcXq1wNviogPAAuA2RExmpk7XaSQmWuANQBDQ0M5PDy817+ITlsffpgfAq9/wxuYdfjhlR5L3RsZGaHq2qs869JM1qV5rEkzNakuVYa1G4FjIuJo4AfA6cAvdzaIiBOBi4CTM3PzxPrM/JWONu+mfRHCs64mrVu22leDOmdNkiTVpbLJV5k5BpwNXAXcBVyamesi4vyIOLVo9inaI2dfiohbI+KKqvqzV0ycxHXOmiRJqkmVI2tk5lpg7ZR153W8PqmL9/hb4G/3dt+ek5wYWettNyRJ0szhEFEZxdWg4X3WJElSTUwdJThnTZIk1c2wVsbEnDVH1iRJUk1MHWVMjKxJkiTVxLBWinPWJElSvUwdJThnTZIk1c2wVoZz1iRJUs1MHWVMzllzZE2SJNXDsFZKMWfNrCZJkmpiWCthcs6ap0ElSVJNTB1lTD4b1KE1SZJUD8NaGcXjphxZkyRJdTF1lFE8yN1xNUmSVBfDWhmOrEmSpJqZOkrwpriSJKluhrUyvCmuJEmqmamjjGJkLRxZkyRJNTGslZKkQU2SJNXIsFbC5Jw1SZKkmhjWyki8uECSJNXKsFZGq2VYkyRJtTKslZKGNUmSVCvDWgnpyJokSaqZYa0M56xJkqSaVRrWIuLkiFgfERsi4pxptn8kIu6MiNsj4pqIOLJYf0JEfDMi1hXbfqnKfnat1fLWHZIkqVaVhbWI6AcuBE4BVgBnRMSKKc1uAYYy83jgMuCCYv2TwK9m5suAk4HPRMTCqvratXTOmiRJqleVI2srgQ2ZeU9mbgcuAU7rbJCZ12bmk8Xi9cCyYv2/Z+bdxesHgM3A4gr72pVM77MmSZLqVWVYWwps7FjeVKzblfcAV05dGRErgdnA9/Zq756LBPocWZMkSfUZqPC9p0s1Oc06IuJMYAhYNWX94cDngbNymmGtiFgNrAYYHBxkZGTkeXZ59w7cuJE5SeXHUTmjo6PWpIGsSzNZl+axJs3UpLpUGdY2Acs7lpcBD0xtFBEnAecCqzJzW8f6g4B/AT6WmddPd4DMXAOsARgaGsrh4eG91vnp/OhrX+eRvj6qPo7KGRkZsSYNZF2aybo0jzVppibVpcrToDcCx0TE0RExGzgduKKzQUScCFwEnJqZmzvWzwYuBz6XmV+qsI+lZHqfNUmSVK/KwlpmjgFnA1cBdwGXZua6iDg/Ik4tmn0KWAB8KSJujYiJMPefgDcD7y7W3xoRJ1TV165leusOSZJUqypPg5KZa4G1U9ad1/H6pF3s9wXgC1X27TlpeesOSZJUL59gUIb3WZMkSTUzrJXgfdYkSVLdDGtlZEKfH5kkSaqLWkyfAAALvUlEQVSPyaOM1rS3iZMkSaqMYa0M56xJkqSaGdbK8D5rkiSpZoa1EtL7rEmSpJoZ1srwPmuSJKlmhrUynLMmSZJqZlgrI1tgVpMkSTUyrJWQmRB+ZJIkqT4mjzK8z5okSaqZYa2MTOjzPKgkSaqPYa2MbJFOWpMkSTUyrJWQXg0qSZJqZlgrw/usSZKkmhnWynBkTZIk1cywVkbL+6xJkqR6GdZKSLzPmiRJqpfJowzvsyZJkmpmWCsjk/Q+a5IkqUaGtTJaLZy0JkmS6mRYK8WrQSVJUr0MayWk91mTJEk1qzSsRcTJEbE+IjZExDnTbP9IRNwZEbdHxDURcWTHtrMi4u7iz1lV9rNr3mdNkiTVrLKwFhH9wIXAKcAK4IyIWDGl2S3AUGYeD1wGXFDsewjwceC1wErg4xGxqKq+dq3VMqxJkqRaVTmythLYkJn3ZOZ24BLgtM4GmXltZj5ZLF4PLCte/zRwdWY+mplbgKuBkyvsa3ccWZMkSTWrMqwtBTZ2LG8q1u3Ke4Arn+O+tWg/yL3XvZAkSTPJQIXvPV2smfaushFxJjAErCqzb0SsBlYDDA4OMjIy8pw62q1FW7cyFlH5cVTO6OioNWkg69JM1qV5rEkzNakuVYa1TcDyjuVlwANTG0XEScC5wKrM3Nax7/CUfUem7puZa4A1AENDQzk8PDy1yV5170Vr2PrUU1R9HJUzMjJiTRrIujSTdWkea9JMTapLladBbwSOiYijI2I2cDpwRWeDiDgRuAg4NTM3d2y6CvipiFhUXFjwU8W63vICA0mSVLPKRtYycywizqYdsvqBizNzXUScD9yUmVcAnwIWAF+Kdgi6PzNPzcxHI+IPaQc+gPMz89Gq+tqt9Ka4kiSpZlWeBiUz1wJrp6w7r+P1SbvZ92Lg4up69xy0vMBAkiTVyycYlJEJ4UcmSZLqY/Ioo9VyZE2SJNXKsFaCc9YkSVLdDGtltJJ0aE2SJNXIsFaGj5uSJEk1M6yV4X3WJElSzQxrpTiyJkmS6mVYKyFbhjVJklQvw1oZzlmTJEk1M6yV4X3WJElSzQxrZWSSjqxJkqQaGdZKyEwcWpMkSXUyrJWRCX2GNUmSVB/DWhmtFo6sSZKkOhnWyvBqUEmSVDPDWglpWJMkSTUzrJVhWJMkSTUzrJXhfdYkSVLNDGtlZJLhRyZJkupj8iihPWet172QJEkziWGtDOesSZKkmhnWyvA+a5IkqWaGtTIcWZMkSTUzrJXgfdYkSVLdKg1rEXFyRKyPiA0Rcc40298cEd+OiLGIeOeUbRdExLqIuCsi/iyiASnJsCZJkmpWWViLiH7gQuAUYAVwRkSsmNLsfuDdwBen7PsG4I3A8cDLgdcAq6rqa9daLdKsJkmSajRQ4XuvBDZk5j0AEXEJcBpw50SDzLy32Naasm8Cc4HZtGf0zwIerLCvXTnyC5/nhjvv3HNDSZKkvaTK06BLgY0dy5uKdXuUmd8ErgV+WPy5KjPv2us9LGnuS19K65BDet0NSZI0g1Q5sjbdCcPsaseIFwPHAcuKVVdHxJsz82tT2q0GVgMMDg4yMjLy3HvbpdHR0VqOo+5Zk2ayLs1kXZrHmjRTk+pSZVjbBCzvWF4GPNDlvu8Ars/MUYCIuBJ4HbBTWMvMNcAagKGhoRweHn6eXd6zkZER6jiOumdNmsm6NJN1aR5r0kxNqkuVp0FvBI6JiKMjYjZwOnBFl/veD6yKiIGImEX74oKenwaVJEmqW2VhLTPHgLOBq2gHrUszc11EnB8RpwJExGsiYhPwi8BFEbGu2P0y4HvAHcBtwG2Z+U9V9VWSJKmpqjwNSmauBdZOWXdex+sbeWZeWmebceB9VfZNkiRpX+ATDCRJkhrMsCZJktRghjVJkqQGM6xJkiQ1mGFNkiSpwSKzq4cKNF5EPATcV8OhDgMeruE46p41aSbr0kzWpXmsSTNVXZcjM3NxNw33m7BWl4i4KTOHet0PPcOaNJN1aSbr0jzWpJmaVBdPg0qSJDWYYU2SJKnBDGvlrel1B/Qs1qSZrEszWZfmsSbN1Ji6OGdNkiSpwRxZkyRJajDDWpci4uSIWB8RGyLinF73ZyaJiIsjYnNEfKdj3SERcXVE3F38vahYHxHxZ0Wdbo+IV/Wu5/uviFgeEddGxF0RsS4iPlysty49FBFzI+KGiLitqMsfFOuPjohvFXX5h4iYXayfUyxvKLYf1cv+7+8ioj8ibomIfy6WrUsPRcS9EXFHRNwaETcV6xr5M8yw1oWI6AcuBE4BVgBnRMSK3vZqRvlb4OQp684BrsnMY4BrimVo1+iY4s9q4C9r6uNMMwb8ZmYeB7wO+GDxb8K69NY24K2Z+UrgBODkiHgd8MfAnxZ12QK8p2j/HmBLZr4Y+NOinarzYeCujmXr0ntvycwTOm7R0cifYYa17qwENmTmPZm5HbgEOK3HfZoxMvNrwKNTVp8GfLZ4/Vng5zrWfy7brgcWRsTh9fR05sjMH2bmt4vXP6b9H9BSrEtPFZ/vaLE4q/iTwFuBy4r1U+syUa/LgLdFRNTU3RklIpYBbwf+V7EcWJcmauTPMMNad5YCGzuWNxXr1DuDmflDaAcHYEmx3lrVrDhFcyLwLaxLzxWn2m4FNgNXA98DtmbmWNGk87OfrEux/THg0Hp7PGN8BvhtoFUsH4p16bUEvhoRN0fE6mJdI3+GDdR1oH3cdL/ReBltM1mrGkXEAuAfgd/IzMd388u/dalJZo4DJ0TEQuBy4LjpmhV/W5caRMTPAJsz8+aIGJ5YPU1T61KvN2bmAxGxBLg6Ir67m7Y9rYkja93ZBCzvWF4GPNCjvqjtwYkh6OLvzcV6a1WTiJhFO6j9XWZ+uVhtXRoiM7cCI7TnFC6MiIlfzjs/+8m6FNsP5tlTDvT8vRE4NSLupT2N5q20R9qsSw9l5gPF35tp/2Kzkob+DDOsdedG4Jjiyp3ZwOnAFT3u00x3BXBW8fos4H93rP/V4sqd1wGPTQxpa+8p5s/8NXBXZn66Y5N16aGIWFyMqBERBwAn0Z5PeC3wzqLZ1LpM1OudwL+lN9/c6zLzdzJzWWYeRfv/j3/LzF/BuvRMRMyPiAMnXgM/BXyHhv4M86a4XYqI/0j7N6F+4OLM/GSPuzRjRMTfA8PAYcCDwMeBrwCXAi8E7gd+MTMfLULEn9O+evRJ4Ncy86Ze9Ht/FhE/CXwduINn5uD8Lu15a9alRyLieNqTovtp/zJ+aWaeHxEvoj2icwhwC3BmZm6LiLnA52nPOXwUOD0z7+lN72eG4jTob2Xmz1iX3ik++8uLxQHgi5n5yYg4lAb+DDOsSZIkNZinQSVJkhrMsCZJktRghjVJkqQGM6xJkiQ1mGFNkiSpwQxrkvQ8RcRwRPxzr/shaf9kWJMkSWoww5qkGSMizoyIGyLi1oi4qHjo+WhE/ElEfDsiromIxUXbEyLi+oi4PSIuj4hFxfoXR8T/iYjbin1+onj7BRFxWUR8NyL+LnbzoFRJKsOwJmlGiIjjgF+i/fDmE4Bx4FeA+cC3M/NVwHW0n5AB8Dngv2bm8bSf1DCx/u+ACzPzlcAbgIlHzpwI/AawAngR7edBStLzNrDnJpK0X3gb8GrgxmLQ6wDaD2luAf9QtPkC8OWIOBhYmJnXFes/C3ypeJbg0sy8HCAznwYo3u+GzNxULN8KHAV8o/ovS9L+zrAmaaYI4LOZ+Ts7rYz4vSntdvcMvt2d2tzW8Xocf75K2ks8DSppprgGeGdELAGIiEMi4kjaPwffWbT5ZeAbmfkYsCUi3lSsfxdwXWY+DmyKiJ8r3mNORMyr9auQNOP4m5+kGSEz74yIjwFfjYg+YAfwQeAJ4GURcTPwGO15bQBnAX9VhLF7gF8r1r8LuCgizi/e4xdr/DIkzUCRubsRf0nav0XEaGYu6HU/JGlXPA0qSZLUYI6sSZIkNZgja5IkSQ1mWJMkSWoww5okSVKDGdYkSZIazLAmSZLUYIY1SZKkBvv/jx/8+7mUIdoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in hist_list[0].keys() :\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.grid(True)    \n",
    "    plt.title('model with noise ' + key)\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel('epoch')\n",
    "    for hist in hist_list :\n",
    "        plt.plot(hist[key])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
