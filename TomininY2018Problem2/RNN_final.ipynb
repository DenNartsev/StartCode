{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.autograd.variable as Variable\n",
    "from torch import optim\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Будем работать с данными акселерометра, поэтому нашей моделью является RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем данные\n",
    "Data = pd.read_csv('WISDM_ar_v1.1_raw.txt', names= [\"user-id\", \"activity\", \"timestamp\", \"x-axis\", \"y-axis\", \"z-axis\"])\n",
    "Data[\"z-axis\"] = [float(str(Element).replace(\";\", \"\")) for Element in Data[\"z-axis\"]]\n",
    "Data.dropna(axis=0,inplace=True)\n",
    "#Data = Data.iloc[np.random.permutation(len(Data))]\n",
    "Data.rename(columns={'user-id':'user'},inplace=True)\n",
    "\n",
    "cl=[\"user\", \"timestamp\", \"x-axis\", \"y-axis\", \"z-axis\"]\n",
    "#Data[cl].astype('float',inplace=True)\n",
    "#print(Data.head())\n",
    "#print(Data.describe())\n",
    "Data = np.array(Data[:int(0.8*len(Data))])\n",
    "Data_test = np.array(Data[int(0.8*len(Data)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    Data[:,i]=Data[:,i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = set()\n",
    "activities = [\"Downstairs\", \"Jogging\", \"Upstairs\", \"Walking\"]\n",
    "for index in range(len(Data)):\n",
    "    users.add(Data[index][0])\n",
    "users = list(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Sort = []\n",
    "y_sort = []\n",
    "activities = [\"Downstairs\", \"Jogging\", \"Upstairs\", \"Walking\"]\n",
    "index = 0\n",
    "while index < len(Data):\n",
    "    Data_current = []\n",
    "    pers = Data[index][0]\n",
    "    act = Data[index][1]\n",
    "    y_sort.append(Data[index][1])\n",
    "    while Data[index][0] == pers and Data[index][1] == act :\n",
    "        Data_current.append(Data[index][2:])\n",
    "        index += 1\n",
    "        if index == len(Data):\n",
    "            break\n",
    "    Data_Sort.append(Data_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_Sort = np.array(Data_Sort)\n",
    "y_sort = np.array(y_sort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sort = np.array(pd.get_dummies(y_sort))\n",
    "type(Data_Sort[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создадим класс, который насследует nn.Module. Переопределим функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.inp = nn.Linear(4, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, 2, dropout=0.05)\n",
    "        self.out = nn.Linear(hidden_size, 6)\n",
    "        self.our=nn.Softmax()\n",
    "    def step(self, input, hidden=None):\n",
    "        #print(f\"input_size={input.size}\")\n",
    "        input = self.inp(input.view(1, -1)).unsqueeze(1)\n",
    "        #print(f\"input2_size={input.size}\")\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "\n",
    "        output = self.out(output.squeeze(1))\n",
    "        output=self.our(output.squeeze(1))\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, inputs, hidden=None, force=True, steps=0):\n",
    "        if force or steps == 0: steps = len(inputs)\n",
    "        outputs = Variable(torch.zeros(steps, 1, 6))\n",
    "        for i in range(steps):\n",
    "            #if force or i == 0:\n",
    "            input = inputs[i]\n",
    "            #else:\n",
    "                #input = output\n",
    "            #pdb.set_trace()\n",
    "            output, hidden = self.step(input, hidden)\n",
    "            outputs[i] = output\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем обучить нашу модель, поралельно будем следить за ошибкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  6., 11.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def accuracy(prediction, answer):\n",
    "    i = 0.\n",
    "    for x, y in zip(prediction, answer):\n",
    "        if(int(x) == int(y)):\n",
    "            i += 1\n",
    "    return i / (len(answer))\n",
    "ts1=torch.tensor([[1,2,6],[3,4,5]],dtype=torch.float32)\n",
    "ts2=torch.tensor([[7,26,66],[34,44,54]],dtype=torch.float32)\n",
    "#accuracy(ts1,ts2)\n",
    "ts1_s=ts1[:][0]\n",
    "for i in range(1,2):\n",
    "    ts1_s+=ts1[:][i]\n",
    "        \n",
    "ts1_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py:167: UserWarning: torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\n",
      "  warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=1.0\n",
      "1 tensor(0.1234)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0\n",
      "2 tensor(0.1247)\n",
      "accuracy=0.0\n",
      "3 tensor(0.1394)\n",
      "accuracy=0.35\n",
      "4 tensor(0.1244)\n",
      "accuracy=0.0\n",
      "5 tensor(0.1389)\n",
      "accuracy=0.95\n",
      "6 tensor(0.1236)\n",
      "accuracy=0.0\n",
      "7 tensor(0.1384)\n",
      "accuracy=1.0\n",
      "8 tensor(0.1231)\n",
      "accuracy=0.0\n",
      "9 tensor(0.1379)\n",
      "accuracy=0.0\n",
      "10 tensor(0.1569)\n",
      "accuracy=0.0\n",
      "11 tensor(0.1251)\n",
      "accuracy=0.0\n",
      "12 tensor(0.1568)\n",
      "accuracy=0.0\n",
      "13 tensor(0.1242)\n",
      "accuracy=0.0\n",
      "14 tensor(0.1565)\n",
      "accuracy=0.6\n",
      "15 tensor(0.1234)\n",
      "accuracy=0.0\n",
      "16 tensor(0.1562)\n",
      "accuracy=1.0\n",
      "17 tensor(0.1226)\n",
      "accuracy=0.0\n",
      "18 tensor(0.1559)\n",
      "accuracy=0.0\n",
      "19 tensor(0.1243)\n",
      "accuracy=0.0\n",
      "20 tensor(0.1387)\n",
      "accuracy=0.4\n",
      "21 tensor(0.1236)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 1\n",
    "n_iters = 100\n",
    "hidden_size = 5\n",
    "\n",
    "model = SimpleRNN(hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "losses = np.zeros(n_iters)  # For plotting\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for n in range(n_iters):\n",
    "        X_train1=Data_Sort[n]\n",
    "        Y_train1=np.array([y_sort[n] for i in range(0,len(X_train1))])\n",
    "        \n",
    "        #ix = np.random.randint(0, len(X_train1), 20)\n",
    "        x_batch = torch.tensor(X_train1, dtype=torch.float32)\n",
    "        y_batch = torch.tensor(Y_train1, dtype=torch.float32)\n",
    "\n",
    "        #force = random.random() < 0.5\n",
    "        #gdb.set_trace()\n",
    "        #pdb.set_trace()\n",
    "        lst=list()\n",
    "        lst_pred=list()\n",
    "        for i in range(0,20):\n",
    "            q1=int(i*len(X_train1)/20)\n",
    "            q2=int((i+1)*len(X_train1)/20)\n",
    "            x_batch_=x_batch[q1:q2]\n",
    "            y_batch_=y_batch[q1:q2]\n",
    "            outputs, hidden = model(x_batch_, None)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_batch_=y_batch_.view(q2-q1,1,6)\n",
    "            lst.append(np.argmax(y_sort[n]))\n",
    "            lst_pred.append(torch.argmax(outputs[-1]))\n",
    "            #print(f\"lst={lst}\")\n",
    "            #y_batch_np=y_batch.view(len(X_train1),6)\n",
    "            #out_np=outputs.view(len(X_train1),6)\n",
    "            #y1=[torch.argmax(y_batch_np[i])for i in range(0,len(X_train1))]\n",
    "            #y1_pred=[torch.argmax(out_np[i])for i in range(0,len(X_train1))]\n",
    "            loss = criterion(outputs, y_batch_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(y1)\n",
    "        acc=accuracy(lst,lst_pred)\n",
    "        print(f\"accuracy={acc}\")\n",
    "        \n",
    "\n",
    "        losses[n] += loss.data[0]\n",
    "\n",
    "        if n > 0:\n",
    "            print(n, loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перейдем на тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    Data_test[:,i]=Data_test[:,i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test = set()\n",
    "activities_test = [\"Downstairs\", \"Jogging\", \"Upstairs\", \"Walking\"]\n",
    "for index in range(len(Data_test)):\n",
    "    users_test.add(Data_test[index][0])\n",
    "users_test = list(users_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Sort_test = []\n",
    "y_sort_test = []\n",
    "activities = [\"Downstairs\", \"Jogging\", \"Upstairs\", \"Walking\"]\n",
    "index = 0\n",
    "while index < len(Data_test):\n",
    "    Data_current_test = []\n",
    "    pers_test = Data_test[index][0]\n",
    "    act_test = Data_test[index][1]\n",
    "    y_sort_test.append(Data_test[index][1])\n",
    "    while Data_test[index][0] == pers_test and Data_test[index][1] == act_test :\n",
    "        Data_current_test.append(Data_test[index][2:])\n",
    "        index += 1\n",
    "        if index == len(Data_test):\n",
    "            break\n",
    "    Data_Sort_test.append(Data_current_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_Sort = np.array(Data_Sort)\n",
    "y_sort_test = np.array(y_sort_test)\n",
    "y_sort_test = np.array(pd.get_dummies(y_sort_test))\n",
    "type(Data_Sort_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_Sort_test[1]\n",
    "#len(Data_Sort_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accc=list()\n",
    "for n in range(60):\n",
    "        X_train1_test=Data_Sort_test[n]\n",
    "        Y_train1_test=np.array([y_sort_test[n] for i in range(0,len(X_train1_test))])\n",
    "        \n",
    "        #ix = np.random.randint(0, len(X_train1), 20)\n",
    "        x_batch_test = torch.tensor(X_train1_test, dtype=torch.float32)\n",
    "        y_batch_test = torch.tensor(Y_train1_test, dtype=torch.float32)\n",
    "\n",
    "        #force = random.random() < 0.5\n",
    "        #gdb.set_trace()\n",
    "        #pdb.set_trace()\n",
    "        lst_test=list()\n",
    "        lst_pred_test=list()\n",
    "        for i in range(0,5):\n",
    "            q1_test=int(i*len(X_train1_test)/20)\n",
    "            q2_test=int((i+1)*len(X_train1_test)/20)\n",
    "            x_batch__test=x_batch_test[q1_test:q2_test]\n",
    "            y_batch__test=y_batch_test[q1_test:q2_test]\n",
    "            outputs_test, hidden_test = model(x_batch__test, None)\n",
    "            y_batch__test=y_batch__test.view(q2_test-q1_test,1,6)\n",
    "            lst_test.append(np.argmax(y_sort_test[n]))\n",
    "            lst_pred_test.append(torch.argmax(outputs_test[-1]))\n",
    "            #print(f\"lst={lst}\")\n",
    "            #y_batch_np=y_batch.view(len(X_train1),6)\n",
    "            #out_np=outputs.view(len(X_train1),6)\n",
    "            #y1=[torch.argmax(y_batch_np[i])for i in range(0,len(X_train1))]\n",
    "            #y1_pred=[torch.argmax(out_np[i])for i in range(0,len(X_train1))]\n",
    "            \n",
    "            #print(y1)\n",
    "        acc_test=accuracy(lst_test,lst_pred_test)\n",
    "        accc.append(acc_test)\n",
    "        print(f\"accuracy={acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построим график\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3=np.linspace(1,100,len(accc))\n",
    "plt.plot(x3,accc)\n",
    "plt.scatter(x3,accc,marker='+')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"nuber a test batch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
