{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataSet:\n",
    "    \n",
    "    def __init__(self, sentence):\n",
    "        self.words2idx = {}\n",
    "        self.indexs  = []\n",
    "        for word in sentence.split(' '): \n",
    "            if word not in self.words2idx:\n",
    "                self.words2idx[word] = len(self.words2idx)\n",
    "                \n",
    "            self.indexs.append(self.words2idx[word])\n",
    "            \n",
    "        self.vec_size = len(self.words2idx)\n",
    "        self.seq_len  = len(sentence.split(' '))\n",
    "        \n",
    "    def get_one_hot(self, idx):\n",
    "        x = torch.zeros(self.vec_size)\n",
    "        x[idx] = 1\n",
    "        return x\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return zip(self.indexs[:-1], self.indexs[1:])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.seq_len\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.words2idx)\n",
    "    \n",
    "    def get_char_by_id(self, id):\n",
    "        for word, i in self.words2idx.items():\n",
    "            if id == i: return word\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size=5, h_size=2, c_size=2, out_size=5):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.x2hidden    = nn.Linear(in_features=in_size, out_features=hidden_size)\n",
    "        self.hidden      = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        self.activation  = nn.Tanh()\n",
    "        self.outweight   = nn.Linear(in_features=hidden_size, out_features=out_size)\n",
    "    \n",
    "    def forward(self, x, prev_hidden):\n",
    "        hidden = self.x2hidden(x) + self.hidden(prev_hidden)\n",
    "        output = self.outweight(hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, size=5, h_size=5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.W_f = nn.Linear(in_features = size+h_size, out_features = h_size)\n",
    "        self.W_i = nn.Linear(in_features = size+h_size, out_features = h_size)\n",
    "        self.W_g = nn.Linear(in_features = size+h_size, out_features = h_size)\n",
    "        self.W_o = nn.Linear(in_features = size+h_size, out_features = h_size)\n",
    "        \n",
    "        self.S_f = nn.Sigmoid()\n",
    "        self.S_i = nn.Tanh()\n",
    "        self.T_g = nn.Sigmoid()\n",
    "        self.S_o = nn.Sigmoid()\n",
    "        \n",
    "        self.T_c = nn.Tanh()\n",
    "        \n",
    "        self.output = nn.Linear(in_features = h_size, out_features = size)\n",
    "        \n",
    "    def forward(self, x, prev_h, prev_c):\n",
    "        stack = torch.cat((x, prev_h), 1)\n",
    "        \n",
    "        f = self.S_f(self.W_f(stack))\n",
    "        i = self.S_i(self.W_i(stack))\n",
    "        g = self.T_g(self.W_g(stack))\n",
    "        o = self.S_o(self.W_o(stack))\n",
    "        \n",
    "        c = f*prev_c + i*g\n",
    "        h = o*self.T_c(prev_c)\n",
    "        \n",
    "        output = self.output(h)\n",
    "        \n",
    "        return output, h, c\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = WordDataSet(sentence=sentence)\n",
    "lstm = LSTM(ds.size(),5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "e_cnt     = 1000\n",
    "optim     = SGD(lstm.parameters(), lr = 0.05)\n",
    "\n",
    "lr_lambda = lambda epoch : 0.99**(epoch/10)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optim, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285.0458984375\n",
      "276.81732177734375\n",
      "254.1818389892578\n",
      "215.6033172607422\n",
      "202.2539520263672\n",
      "130.3117218017578\n",
      "98.00276947021484\n",
      "82.61087036132812\n",
      "72.87003326416016\n",
      "65.10380554199219\n",
      "56.54714584350586\n",
      "51.07998275756836\n",
      "47.371498107910156\n",
      "43.31869125366211\n",
      "40.46412658691406\n",
      "38.037254333496094\n",
      "35.34675216674805\n",
      "33.406532287597656\n",
      "31.961816787719727\n",
      "29.891677856445312\n",
      "28.434906005859375\n",
      "27.379499435424805\n",
      "25.974565505981445\n",
      "24.872848510742188\n",
      "23.889236450195312\n",
      "22.989439010620117\n",
      "22.172819137573242\n",
      "21.422584533691406\n",
      "20.73621368408203\n",
      "20.104248046875\n",
      "19.52216339111328\n",
      "18.98406410217285\n",
      "18.4847412109375\n",
      "18.019922256469727\n",
      "17.58625602722168\n",
      "17.180824279785156\n",
      "16.801042556762695\n",
      "16.44463539123535\n",
      "16.109582901000977\n",
      "15.794071197509766\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(e_cnt):\n",
    "    scheduler.step()\n",
    "    h = Variable( torch.zeros(5) ).unsqueeze(0)\n",
    "    c = Variable( torch.zeros(5) ).unsqueeze(0)\n",
    "    loss = 0\n",
    "    optim.zero_grad()\n",
    "    for sample, next_sample in ds:\n",
    "        x = Variable(  ds.get_one_hot(sample) ).unsqueeze(0)\n",
    "        target =  Variable(torch.LongTensor([next_sample]) )\n",
    "\n",
    "        y, h, c = lstm(x, h, c)\n",
    "        \n",
    "        loss += criterion(y, target)\n",
    "     \n",
    "    if epoch % 25 == 0:\n",
    "        print (loss.data[0])\n",
    "        \n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "lstm.eval()\n",
    "h = Variable( torch.zeros(5) ).unsqueeze(0)\n",
    "c = Variable( torch.zeros(5) ).unsqueeze(0)\n",
    "id = 0\n",
    "softmax = nn.Softmax()\n",
    "predsentence = ds.get_char_by_id(id) + ' '\n",
    "for w in range(len(ds)-1):\n",
    "    x = Variable(ds.get_one_hot(id)).unsqueeze(0)\n",
    "    y, h, c = lstm(x, h, c)\n",
    "    y = softmax(y)\n",
    "    m, id = torch.max(y, 1)\n",
    "    id = id.data[0]\n",
    "    predsentence += ds.get_char_by_id(id) + ' '\n",
    "print ('Prediction: ' , predsentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
